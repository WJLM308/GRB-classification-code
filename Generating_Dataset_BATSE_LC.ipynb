{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b48ade05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error with basic_table.csv\n",
      "error with duration_table.csv\n",
      "error with GRB1200.csv\n",
      "100 files done\n",
      "error with GRB1518.csv\n",
      "error with GRB1533.csv\n",
      "error with GRB1540.csv\n",
      "error with GRB1541.csv\n",
      "error with GRB1546.csv\n",
      "error with GRB1553.csv\n",
      "error with GRB1558.csv\n",
      "error with GRB1561.csv\n",
      "error with GRB1567.csv\n",
      "error with GRB1586.csv\n",
      "error with GRB1588.csv\n",
      "error with GRB1590.csv\n",
      "200 files done\n",
      "error with GRB2213.csv\n",
      "300 files done\n",
      "400 files done\n",
      "error with GRB2463.csv\n",
      "error with GRB2504.csv\n",
      "error with GRB2513.csv\n",
      "error with GRB2529.csv\n",
      "error with GRB2536.csv\n",
      "error with GRB254.csv\n",
      "error with GRB2542.csv\n",
      "error with GRB2551.csv\n",
      "500 files done\n",
      "600 files done\n",
      "error with GRB3099.csv\n",
      "700 files done\n",
      "error with GRB3251.csv\n",
      "error with GRB3253.csv\n",
      "error with GRB3431.csv\n",
      "800 files done\n",
      "error with GRB3580.csv\n",
      "error with GRB3709.csv\n",
      "error with GRB3711.csv\n",
      "error with GRB3803.csv\n",
      "900 files done\n",
      "error with GRB3911.csv\n",
      "error with GRB3915.csv\n",
      "error with GRB3938.csv\n",
      "1000 files done\n",
      "error with GRB5496.csv\n",
      "1100 files done\n",
      "error with GRB5693.csv\n",
      "1200 files done\n",
      "error with GRB6109.csv\n",
      "error with GRB6125.csv\n",
      "error with GRB6144.csv\n",
      "error with GRB6229.csv\n",
      "1300 files done\n",
      "error with GRB6358.csv\n",
      "error with GRB6400.csv\n",
      "error with GRB6432.csv\n",
      "error with GRB6433.csv\n",
      "1400 files done\n",
      "1500 files done\n",
      "1600 files done\n",
      "1700 files done\n",
      "error with GRB7521.csv\n",
      "error with GRB7523.csv\n",
      "1800 files done\n",
      "error with GRB7854.csv\n",
      "error with GRB7965.csv\n",
      "1900 files done\n",
      "error with GRB8071.csv\n",
      "error with GRB878.csv\n",
      "LightCurves normalised and cut\n",
      "100 lightcurves padded\n",
      "200 lightcurves padded\n",
      "300 lightcurves padded\n",
      "400 lightcurves padded\n",
      "500 lightcurves padded\n",
      "600 lightcurves padded\n",
      "700 lightcurves padded\n",
      "800 lightcurves padded\n",
      "900 lightcurves padded\n",
      "1000 lightcurves padded\n",
      "1100 lightcurves padded\n",
      "1200 lightcurves padded\n",
      "1300 lightcurves padded\n",
      "1400 lightcurves padded\n",
      "1500 lightcurves padded\n",
      "1600 lightcurves padded\n",
      "1700 lightcurves padded\n",
      "1800 lightcurves padded\n",
      "1900 lightcurves padded\n",
      "              0             1             2             3             4     \\\n",
      "1009  2.170896e+06  3.376899e+06 -5.266793e+04 -8.132904e+05  2.170701e+06   \n",
      "1025 -6.384340e+06  3.115795e+06  9.330865e+06  1.460645e+06 -4.468247e+06   \n",
      "1036  3.715748e+06  3.390271e+06  1.567845e+06 -1.206464e+06  3.716089e+06   \n",
      "1039  2.661215e+06  2.520288e+07  3.686519e+06 -5.005812e+06  9.200980e+06   \n",
      "1042 -8.114799e+03  3.403005e+05 -1.307075e+06 -1.497817e+06 -7.627684e+03   \n",
      "...            ...           ...           ...           ...           ...   \n",
      "942   2.000238e+07  3.519585e+07  4.495152e+07  7.048906e+06  3.072213e+07   \n",
      "946   1.650357e+06  4.666677e+06  2.600984e+06  6.286243e+05  1.649438e+06   \n",
      "973   1.688052e+05  2.292729e+04  1.276621e+05 -9.415733e+04  3.634626e+05   \n",
      "974   1.542258e+07  1.742529e+07  1.448265e+07  5.076419e+06  6.398487e+06   \n",
      "999   3.090410e+06  8.454796e+06  4.995836e+06  1.048339e+06  4.592293e+06   \n",
      "\n",
      "              5             6             7             8             9     \\\n",
      "1009  8.199932e+05  1.462358e+06  1.336319e+05  8.723190e+04  3.092495e+06   \n",
      "1025  1.075858e+07  1.274337e+07  3.506628e+06 -3.643126e+06 -8.757476e+03   \n",
      "1036  3.390453e+06  1.568283e+06 -1.205787e+06  3.716430e+06  3.390636e+06   \n",
      "1039  2.029904e+07  1.553803e+07 -5.104243e+05  3.889305e+06  2.234259e+07   \n",
      "1042  3.397831e+05 -1.309609e+06 -1.500003e+06 -7.140570e+03  3.392658e+05   \n",
      "...            ...           ...           ...           ...           ...   \n",
      "942   4.234275e+07  3.423720e+07 -1.285679e+06  3.310763e+07  1.615263e+07   \n",
      "946   4.665874e+06  2.600418e+06  6.287606e+05  1.648519e+06  4.665071e+06   \n",
      "973   2.917038e+05  4.510127e+04  7.999880e+03  3.635765e+05  2.917581e+05   \n",
      "974   3.186758e+07  2.892367e+07 -7.559227e+06  1.632805e+07  2.103833e+07   \n",
      "999   4.831809e+06  7.293221e+06  1.490109e+06  4.503655e+06  6.333833e+06   \n",
      "\n",
      "      ...  8058  8059  8060  8061  8062  8063  8064  8065  8066  8067  \n",
      "1009  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1025  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1036  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1039  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1042  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "942   ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "946   ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "973   ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "974   ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "999   ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[1911 rows x 8068 columns]\n"
     ]
    }
   ],
   "source": [
    "'''Swift specific but good foe inspirations'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import ceil, floor\n",
    "import os\n",
    "\n",
    "# Read files\n",
    "duration_data = pd.read_pickle(\"DataFrames/duration_data_BATSE.dat\")\n",
    "fluence_data = pd.read_pickle(\"DataFrames/fluence_data_BATSE.dat\")\n",
    "\n",
    "def cut_norm_lc(filename): #Prepare single light curve, cut to T90 and normalize by fluence\n",
    "    trigger = int(filename[6:-4])\n",
    "    #Cut lightcurve\n",
    "    file = pd.read_csv(filename, skiprows=1, header=None, sep='\\s+')\n",
    "    times = pd.DataFrame(fits.open(f'BATSE/GRB{trigger}.fits')[2].data.field('TIMES'))\n",
    "    header = pd.Series(data=file.loc[0].values, index=['trig#', 'npts', 'nlasc', '1preb'], dtype='int64')\n",
    "    trig_time = header['nlasc'] + 32\n",
    "    lc = file.drop(0).reset_index(drop=True)\n",
    "    for i in range(4):\n",
    "        b1 = lc.iloc[0,i]\n",
    "        b2 = lc.iloc[-1,i]\n",
    "        lc.iloc[:,i] = lc.iloc[:,i] - [b1 + (b2-b1)/(len(lc)-1)*i for i in range(len(lc))]\n",
    "    start = trig_time + floor(max([times.min().min(), duration_data.loc[trigger,'start_T90']])/0.064)\n",
    "    end = trig_time + ceil(min([times.max().max(), duration_data.loc[trigger,'start_T90']+duration_data.loc[trigger,'T90']])/0.064) - 1\n",
    "    lc = lc.loc[start:end]\n",
    "    #lc = lc.loc[(trig_time + duration_data.loc[trigger,'start_T90']/0.064):(trig_time + (duration_data.loc[trigger,'start_T90'] + duration_data.loc[trigger,'T90'])/0.064 - 1)]\n",
    "    lc.reset_index(drop=True,inplace=True)\n",
    "    lc = lc.iloc[:,[0,1,2,3]] / float(fluence_data.loc[trigger,'fluence'])\n",
    "    return len(lc), lc # Return length and the cut lightcurve\n",
    "\n",
    "\n",
    "def prepare_lcs():\n",
    "    # Go through all LightCurves in the folder BATSE and prepare them\n",
    "    path = \"LC/\"\n",
    " \n",
    "    unpadded_curves = []\n",
    "    grbnames = []\n",
    "    errors = []\n",
    "\n",
    "    # Go through all the files\n",
    "    max_len = 0 # Record longest burst\n",
    "    count = 1\n",
    "\n",
    "    error_log = \"\"\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        try:     \n",
    "            if count % 100 == 0:\n",
    "                print(f\"{count} files done\")\n",
    "            count += 1\n",
    "            length, lc = cut_norm_lc(path + file)\n",
    "            if length < 1:\n",
    "                error_log += f\"{file[:-4]} \\t Too short \\n\"\n",
    "                continue\n",
    "            unpadded_curves.append(lc)\n",
    "            grbnames.append(file[3:-4])\n",
    "            if length > max_len:\n",
    "                max_len = length\n",
    "        except Exception as e: # If we recieve an error we log it\n",
    "            errors.append(file)\n",
    "            error_log += f\"{file[:-4]} \\t {e} \\n\"\n",
    "            print(f\"error with {file}\")\n",
    "        # os.remove(path + file)\n",
    "    \n",
    "    # save backup for debugging purposes\n",
    "    print(\"LightCurves normalised and cut\")\n",
    "    pd.to_pickle([unpadded_curves, grbnames, errors, max_len], \"backup_BATSE_LC.dat\")\n",
    "\n",
    "    # Load backup\n",
    "    # (unpadded_curves, grbnames, errors, max_len) = pd.read_pickle(\"backup_BATSE_LC.dat\")\n",
    "\n",
    "    prepared_lcs = []\n",
    "\n",
    "    # Go through and pad\n",
    "    count = 0\n",
    "    for lc in unpadded_curves:\n",
    "        temp = np.zeros(shape = (max_len, 4))\n",
    "        temp[:len(lc), :] = lc\n",
    "        prepared_lcs.append(temp.reshape(-1))\n",
    "        count += 1\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            print(f\"{count} lightcurves padded\")\n",
    "\n",
    "    del unpadded_curves\n",
    "\n",
    "    # Make to DataFrame\n",
    "    prepared_dataset = pd.DataFrame(prepared_lcs)\n",
    "    prepared_dataset.index = grbnames[:len(prepared_dataset)]\n",
    "    prepared_dataset.index = grbnames\n",
    "    rows_with_inf = prepared_dataset[prepared_dataset.apply(lambda x: any(np.isinf(x)), axis=1)]\n",
    "    prepared_dataset.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    prepared_dataset = prepared_dataset.dropna()\n",
    "    prepared_dataset.to_pickle('non_fft_dataset_BATSE_LC.dat')\n",
    "    print(prepared_dataset)\n",
    "\n",
    "     # Write errors to log\n",
    "    err_file = open(\"Error_log_BATSE_LC.txt\", \"w\")\n",
    "    err_file.write(error_log)\n",
    "    err_file.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prepare_lcs()\n",
    "    \n",
    "# Any following error message is probably due to missing fluence data -- nothing we can do about it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
