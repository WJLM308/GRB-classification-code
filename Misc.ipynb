{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35718d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from astropy.utils.data import download_file\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import warnings\n",
    "import shutil\n",
    "from astropy.io import fits\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "from astropy.io import ascii\n",
    "from astropy.coordinates import SkyCoord\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from playsound import playsound\n",
    "import requests\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import HoverTool, MultiChoice, CustomJS, ColumnDataSource, LinearColorMapper, CategoricalColorMapper, ColorBar\n",
    "from bokeh.layouts import column\n",
    "from bokeh.palettes import Plasma256\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.Dark2.colors)\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e31ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4025dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hardness_data_swift = pd.read_pickle('DataFrames/hardness_data.dat')\n",
    "display(hardness_data_swift)\n",
    "print(hardness_data_swift.loc['GRB140716A-1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7205ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fluence_data_swift = pd.read_pickle('DataFrames/fluence_data.dat')\n",
    "display(fluence_data_swift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6bf3c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fluence_data_BATSE = pd.read_pickle('DataFrames/fluence_data_BATSE.dat')\n",
    "display(fluence_data_BATSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f82074",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.read_pickle(\"DataFrames/duration_data_BATSE.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f71c1b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.read_pickle(\"DataFrames/hardness_data_BATSE.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c35bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle(\"DataFrames/peak_flux_BATSE.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9211eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.read_pickle(\"DataFrames/duration_data.dat\").loc['GRB061210']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f08a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle(\"DataFrames/duration_data.dat\").loc['GRB090531B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e8768",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('DataFrames/fluence_data_Fermi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('DataFrames/duration_data_Fermi.csv', index_col=0).loc['GRB200826187']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98fd4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_swift = pd.read_csv(\"LightCurves/GRB041217_lc.dat\", sep = ' ', header = None)\n",
    "lc_swift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57c75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = fits.open('Fermi/bn080714086.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5569ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb8bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file[0].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de15ebc5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file[2].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a862958",
   "metadata": {},
   "outputs": [],
   "source": [
    "file[2].data.field('PARAM1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd025f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = file[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d6f89d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data.data.field('NRGFLNC')).loc[:,0].sum()/417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d2e90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b963627",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data.field('TIMEBIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8289ec3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full = fits.open('Fermi/bn080714086.fit')[2].data.field('NRGFLUX')\n",
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5552391",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(fits.open('Fermi/bn080724401.fit')[2].data.field('NRGFLUX'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluence_data = pd.read_csv('DataFrames/fluence_data_Fermi.csv', index_col=0)\n",
    "fluence_data.loc['GRB200826187','fluence'] = '4.8E-06'\n",
    "\n",
    "def normalize_lc(filename): # Normalize by fluence\n",
    "    grbname = filename[8:-4]\n",
    "    #Cut lightcurve\n",
    "    lc = pd.DataFrame(fits.open(filename)[2].data.field('NRGFLUX'))\n",
    "    lc = lc.squeeze() / float(fluence_data.loc[f'GRB{grbname}','fluence'])\n",
    "    return len(lc), lc # Return length and the normalized lightcurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df145f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(normalize_lc('Fermi/bn090510016.fit')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de63d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fluence_data.loc['GRB180201780','fluence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(normalize_lc('Fermi/bn080727964.fit')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1bf7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_lc('Fermi/bn080727964.fit')\n",
    "print(fluence_data.loc['GRB080727964','fluence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c0b6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits.open('Fermi/bn080727964.fit')[2].data.field('NRGFLUX')[215:217]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f733c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#duration = pd.read_pickle('DataFrames/duration_data.dat')\n",
    "#duration.loc['GRB211211A'] = ['1088940', 2.932, 53.256, np.NaN, np.NaN, 50.324]\n",
    "#duration = duration.sort_values('GRBname', ascending=False)\n",
    "#duration.to_pickle(\"DataFrames/duration_data.dat\")\n",
    "#display(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5d5acf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#fluence = pd.read_pickle('DataFrames/fluence_data.dat').to_frame().reset_index()\n",
    "#fluence.loc[len(fluence.index)] = ['GRB211211A','2.52e-04']\n",
    "#fluence.columns = ['GRBname', 'fluence']\n",
    "#fluence = fluence.sort_values('GRBname', ascending=False).set_index('GRBname')\n",
    "#fluence = fluence.squeeze()\n",
    "#fluence.to_pickle(\"DataFrames/fluence_data.dat\")\n",
    "#display(fluence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6178911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = fits.open(\"BATSE/GRB105.fits\")\n",
    "f.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e406d95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f[0].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b28006d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(f[2].data.field('TIMES'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d1fe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(f[2].data.field('RATES'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c321e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(f[2].data.field('TIMES')[:,0]), pd.DataFrame(f[2].data.field('RATES'))], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1720f3f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "duration_data = pd.read_pickle(\"DataFrames/duration_data_BATSE.dat\")\n",
    "fluence_data = pd.read_pickle(\"DataFrames/fluence_data_BATSE.dat\")\n",
    "data_problems = pd.read_pickle(\"DataFrames/data_problems_BATSE.dat\")\n",
    "outliers = pd.read_pickle(\"DataFrames/outliers_BATSE.dat\")\n",
    "\n",
    "\n",
    "def cut_norm_lc(filename): #Prepare single light curve, cut to T90 and normalize by fluence\n",
    "    trigger = int(filename[9:-5])\n",
    "    #Cut lightcurve\n",
    "    lc = pd.concat([pd.DataFrame(fits.open(filename)[2].data.field('TIMES')[:,0]), pd.DataFrame(fits.open(filename)[2].data.field('RATES'))], axis = 1, ignore_index = True)\n",
    "    #if str(trigger) in data_problems.index:\n",
    "        #lc = lc.drop(index=data_problems.loc[str(trigger),'location'])\n",
    "    if str(trigger) in list(outliers):\n",
    "        return None\n",
    "    lc = lc.loc[lc.loc[:,0].apply(lambda x: duration_data.loc[trigger,'start_T90'] <= x and x <= (duration_data.loc[trigger,'start_T90'] + duration_data.loc[trigger,'T90']))]\n",
    "    lc.reset_index(drop=True,inplace=True)\n",
    "    lc = lc.iloc[:,[1,2,3,4]] / float(fluence_data.loc[trigger, 'fluence'])\n",
    "    return len(lc), lc # Return length and the cut lightcurve\n",
    "\n",
    "cut_norm_lc('BATSE/GRB5458.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f0083",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fits.open(\"BATSE/GRB5458.fits\")[2].data.field('RATES'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2520de12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lc = pd.DataFrame(fits.open('BATSE/GRB5992.fits')[2].data.field('RATES').byteswap().newbyteorder())[80:90]\n",
    "fluence_data = pd.read_pickle(\"DataFrames/fluence_data_BATSE.dat\")\n",
    "duration_data = pd.read_pickle(\"DataFrames/duration_data_BATSE.dat\")\n",
    "data_problems = pd.read_pickle(\"DataFrames/data_problems_BATSE.dat\")\n",
    "for trigger in list(data_problems.index):\n",
    "    filename = f'BATSE/GRB{trigger}.fits'\n",
    "    trigger = int(trigger)\n",
    "    print(trigger)\n",
    "    display(duration_data.loc[trigger])\n",
    "    lc = pd.concat([pd.DataFrame(fits.open(filename)[2].data.field('TIMES')), pd.DataFrame(fits.open(filename)[2].data.field('RATES'))], axis = 1, ignore_index = True)\n",
    "    lc.loc[data_problems.loc[str(trigger),'location']] /= 100\n",
    "    lc = lc.loc[lc.loc[:,0].apply(lambda x: duration_data.loc[trigger,'start_T90'] <= x and x <= (duration_data.loc[trigger,'start_T90'] + duration_data.loc[trigger,'T90']))]\n",
    "    lc.iloc[:,0] = pd.to_timedelta(pd.Series(lc.iloc[:,0]), unit = 's')\n",
    "    lc.iloc[:,1] = pd.to_timedelta(pd.Series(lc.iloc[:,1]), unit = 's')\n",
    "    lc = lc.resample('64ms', on=0).mean().bfill()\n",
    "    lc.reset_index(drop=True,inplace=True)\n",
    "    lc = lc.loc[:,[2,3,4,5]]\n",
    "    display(lc)\n",
    "    plt.plot(lc)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae4a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluence_data = pd.read_pickle(\"DataFrames/fluence_data_BATSE.dat\")\n",
    "duration_data = pd.read_pickle(\"DataFrames/duration_data_BATSE.dat\")\n",
    "data_problems = pd.read_pickle(\"DataFrames/data_problems_BATSE.dat\")\n",
    "\n",
    "def cut_norm_lc(filename): #Prepare single light curve, cut to T90 and normalize by fluence\n",
    "    trigger = int(filename[9:-5])\n",
    "    #Cut lightcurve\n",
    "    lc = pd.concat([pd.DataFrame(fits.open(filename)[2].data.field('TIMES')), pd.DataFrame(fits.open(filename)[2].data.field('RATES'))], axis = 1, ignore_index = True)\n",
    "    if str(trigger) in data_problems.index:\n",
    "        lc.loc[data_problems.loc[str(trigger),'location']] /= 100\n",
    "    #if f'GRB{str(trigger)}' in list(outliers):\n",
    "        #lc = lc.drop(index=data_problems.loc[str(trigger),'location'])\n",
    "    lc = lc.loc[lc.loc[:,0].apply(lambda x: duration_data.loc[trigger,'start_T90'] <= x and x <= (duration_data.loc[trigger,'start_T90'] + duration_data.loc[trigger,'T90']))]\n",
    "    #lc = lc[lc[1] - lc[0] <= 0.006]\n",
    "    lc.reset_index(drop=True,inplace=True)\n",
    "    #lc = lc.iloc[:,[1,2,3,4]] / float(fluence_data.loc[trigger,'fluence'])\n",
    "    lc.iloc[:,0] = pd.to_timedelta(pd.Series(lc.iloc[:,0]), unit = 's')\n",
    "    lc.iloc[:,1] = pd.to_timedelta(pd.Series(lc.iloc[:,1]), unit = 's')\n",
    "    print(lc.iloc[:,1] - lc.iloc[:,0])\n",
    "    lc = lc.resample('64ms', on=0).mean().pad()\n",
    "    lc.reset_index(drop=True,inplace=True)\n",
    "    lc = lc.loc[:,[2,3,4,5]] / float(fluence_data.loc[trigger,'fluence'])\n",
    "    return len(lc), lc # Return length and the cut lightcurve\n",
    "trig = 8121\n",
    "print(duration_data.loc[trig,'T90']/0.064)\n",
    "cut_norm_lc(f'BATSE/GRB{trig}.fits')\n",
    "plt.plot(cut_norm_lc(f'BATSE/GRB{trig}.fits')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e075e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(f[2].data.field('TIMES').byteswap().newbyteorder())\n",
    "trigger = 1192\n",
    "data = data.loc[data.loc[:,0].apply(lambda x: duration_data.loc[trigger,'start_T90'] <= x and x <= (duration_data.loc[trigger,'start_T90'] + duration_data.loc[trigger,'T90']))]\n",
    "#data = data.loc[data.loc[:,0].apply(lambda x: duration_data.loc[trigger,'start_T90'] <= x and x <= (duration_data.loc[trigger,'start_T90'] + duration_data.loc[trigger,'T90']))]\n",
    "data = data[data[1] - data[0] <= 0.005]\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    #print(data)\n",
    "    print(data[1] - data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7cf38a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cd4b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"BATSE/GRB6137.fits\"\n",
    "lc = pd.concat([pd.DataFrame(fits.open(filename)[2].data.field('TIMES')[:,0]), pd.DataFrame(fits.open(filename)[2].data.field('RATES'))], axis = 1, ignore_index = True)\n",
    "lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03375e85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"BATSE/\"\n",
    "trig = []\n",
    "loc = []\n",
    "'''\n",
    "for file in os.listdir(path):\n",
    "    df = pd.DataFrame(fits.open(path + file)[2].data.field('RATES').byteswap().newbyteorder())\n",
    "    if (df>50000).any(1).any():\n",
    "        index = list(df.loc[(df>50000).any(1)].index)\n",
    "        check_outlier = (df.iloc[index[0]][0] > 10 * df.iloc[index[0]-1][0]) and (df.iloc[index[0]][0] > 10 * df.iloc[index[0]+1][0])\n",
    "        if check_outlier:\n",
    "            print(file)\n",
    "            print(index)\n",
    "            i = index[0]\n",
    "            print(df[i-2:i+3])\n",
    "            if len(index) < 5:\n",
    "                trig.append(file[3:-5])\n",
    "                loc.append(index)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1957b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d452b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_problems = pd.DataFrame(data={'Trigger':trig,'location':loc}).set_index('Trigger')\n",
    "display(data_problems)\n",
    "#data_problems.to_pickle(\"DataFrames/data_problems_BATSE.dat\")\n",
    "print(data_problems.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'BATSE/GRB1453.fits'\n",
    "trigger = 1453\n",
    "lc = pd.concat([pd.DataFrame(fits.open(filename)[2].data.field('TIMES')[:,0]), pd.DataFrame(fits.open(filename)[2].data.field('RATES'))], axis = 1, ignore_index = True)\n",
    "if str(trigger) in data_problems.index:\n",
    "    lc = lc.drop(index=data_problems.loc[str(trigger),'location'])\n",
    "    display(lc[80:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bd4810",
   "metadata": {},
   "outputs": [],
   "source": [
    "old = pd.read_table('Classifications.txt', sep = '\\s+', skiprows = 14, names = ['GRBname', 'fluence', 'type']).set_index('GRBname')\n",
    "#old[]\n",
    "# 1254 total bursts included\n",
    "old[(old == 'Discarded').any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfdc2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.read_pickle('DataFrames/classification.dat')\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cbee93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "union = pd.concat([old.loc[:, 'type'], new], axis=1, ignore_index=True)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(union[union[0] != union[1]].dropna())\n",
    "\n",
    "#GRB180418A\n",
    "#GRB121226A\n",
    "#GRB050724"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b88395",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = pd.read_csv('DataFrames/classification_BATSE.txt', index_col=0)\n",
    "cat2 = pd.read_csv('DataFrames/classification_BATSE_UMAP.txt', index_col=0)\n",
    "union = pd.concat([cat1.loc[:, 'type'], cat2], axis=1, ignore_index=True)\n",
    "miscat = union[union[0] != union[1]]\n",
    "miscat.columns = ['t-SNE', 'UMAP']\n",
    "len(miscat.index)\n",
    "miscat.groupby(miscat.UMAP).get_group('S').size/2\n",
    "#miscat.to_csv('DataFrames/mismatching_bursts_BATSE.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = pd.read_csv('DataFrames/classification_BATSE_UMAP.txt', index_col=0)\n",
    "cat1.groupby(cat1.type).get_group('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ae4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data = pd.read_pickle('DataFrames/duration_data.dat')\n",
    "fluence_data = pd.read_pickle('DataFrames/fluence_data.dat')\n",
    "\n",
    "\n",
    "def cut_norm_lc(filename): #Prepare single light curve, cut to T100 and normalize by fluence\n",
    "    grbname = filename[12:-7]\n",
    "    #Cut lightcurve\n",
    "    lc = pd.read_csv(filename, sep = ' ', header = None)\n",
    "    lc = lc.loc[:, [0, 1, 3, 5, 7]]\n",
    "    lc = lc.loc[lc.loc[:,0].apply(lambda x: duration_data.T100_start[grbname] <= x and x <= duration_data.T100_end[grbname])]\n",
    "    lc.reset_index(drop=True,inplace=True)\n",
    "    lc = lc.iloc[:,[1,2,3,4]] / float(fluence_data.loc[grbname, 'fluence'])\n",
    "    return len(lc), lc # Return length and the cut lightcurve\n",
    "\n",
    "print(cut_norm_lc('LightCurves/GRB041219B_lc.dat'))\n",
    "print(duration_data.loc['GRB041219B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce23600",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(cut_norm_lc('LightCurves/GRB041219B_lc.dat')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e445db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(cut_norm_lc('LightCurves/GRB050724_lc.dat')[1])\n",
    "cut_norm_lc('LightCurves/GRB050724_lc.dat')[0]\n",
    "duration_data.loc['GRB041219B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed9218e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#problem_files = list(pd.read_table('Error_log.txt', on_bad_lines = 'skip', header = None)[0].str.strip())\n",
    "#for file in problem_files:\n",
    "    #lc = cut_norm_lc(f'LightCurves/{file}_lc.dat')\n",
    "    #print(file)\n",
    "    #print(lc[0])\n",
    "    #plt.plot(lc[1])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2285f49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(pd.read_pickle('DataFrames/outliers_BATSE.dat'))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cbdcaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for grb in list(pd.Series(pd.read_pickle('DataFrames/outliers_BATSE.dat'))):\n",
    "    #print(grb)\n",
    "    #plt.plot(cut_norm_lc(f'BATSE/{grb}.fits')[1])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8414052",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "duration = pd.read_pickle(\"DataFrames/duration_data.dat\").iloc[:,[1,2,3,4]]\n",
    "fluence = pd.read_pickle('DataFrames/fluence_data.dat')\n",
    "display(fluence)\n",
    "hardness = pd.read_pickle('DataFrames/hardness_data.dat')\n",
    "summary = pd.concat([duration, fluence, hardness], axis=1)\n",
    "#display(summary)\n",
    "#summary.to_csv('summary_Swift.csv')\n",
    "print(summary.T100_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9357196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_norm_lc(filename): #Prepare single light curve, cut to T100 and normalize by fluence\n",
    "    grbname = filename[12:-7]\n",
    "    #Cut lightcurve\n",
    "    lc = pd.read_csv(filename, sep = ' ', header = None)\n",
    "    lc = lc.loc[:, [0, 1, 3, 5, 7]]\n",
    "    lc = lc.loc[lc.loc[:,0].apply(lambda x: summary.T100_start[grbname] <= x and x <= summary.T100_end[grbname])]\n",
    "    lc.reset_index(drop=True,inplace=True)\n",
    "    lc = lc.iloc[:,[1,2,3,4]] / float(summary.fluence[grbname])\n",
    "    return len(lc), lc # Return length and the cut lightcurve\n",
    "plt.plot(cut_norm_lc('LightCurves/GRB121226A_lc.dat')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e60d021",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary = pd.read_csv('summary_Swift.csv', index_col=0)#.set_index('GRBname')\n",
    "#summary.to_csv('summary_Swift.csv')\n",
    "display(summary)\n",
    "def cut_norm_lc(filename): #Prepare single light curve, cut to T100 and normalize by fluence\n",
    "    grbname = filename[12:-7]\n",
    "    #Cut lightcurve\n",
    "    lc = pd.read_csv(filename, sep = ' ', header = None)\n",
    "    lc = lc.loc[:, [0, 1, 3, 5, 7]]\n",
    "    lc = lc.loc[lc.loc[:,0].apply(lambda x: summary.T100_start[grbname] <= x and x <= summary.T100_end[grbname])]\n",
    "    lc.reset_index(drop=True,inplace=True)\n",
    "    lc = lc.iloc[:,[1,2,3,4]] / float(summary.fluence[grbname])\n",
    "    return len(lc), lc # Return length and the cut lightcurve\n",
    "cut_norm_lc('LightCurves/GRB050724_lc.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ccbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_url = f'https://heasarc.gsfc.nasa.gov/FTP/compton/data/batse/trigger/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e9da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_url_paths(url, ext='', params={}):\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.ok:\n",
    "        response_text = response.text\n",
    "    else:\n",
    "        return response.raise_for_status()\n",
    "    soup = BeautifulSoup(response_text, 'html.parser')\n",
    "    parent = [url + node.get('href') for node in soup.find_all('a') if '00' in node.get('href')]\n",
    "    return parent\n",
    "\n",
    "url = 'https://heasarc.gsfc.nasa.gov/FTP/compton/data/batse/ascii_data/64ms/'\n",
    "ext = ''\n",
    "result = get_url_paths(url, ext)\n",
    "#print(result)\n",
    "print(len(result))\n",
    "\n",
    "def get_url_paths2(url, ext='', params={}):\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.ok:\n",
    "        response_text = response.text\n",
    "    else:\n",
    "        return response.raise_for_status()\n",
    "    soup = BeautifulSoup(response_text, 'html.parser')\n",
    "    parent = [url + node.get('href') for node in soup.find_all('a')]\n",
    "    return parent\n",
    "\n",
    "url = 'https://heasarc.gsfc.nasa.gov/FTP/compton/data/batse/ascii_data/64ms/'\n",
    "ext = ''\n",
    "result2 = []\n",
    "for path in result:\n",
    "    print(get_url_paths2(path,ext))\n",
    "print()\n",
    "for path in result:\n",
    "    print(len(get_url_paths2(path, ext)))\n",
    "    result2 += get_url_paths2(path, ext)\n",
    "print()\n",
    "print(len(result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bursts = pd.DataFrame(result2)[0].str[74:78]\n",
    "GRB_Names = pd.read_table(\"summary/Basic_BATSE_new.dat\", sep=\"\\s+\", comment='#', header=None, usecols=[0,1,2],index_col=0)\n",
    "#for burst in bursts:\n",
    "    #if int(burst) not in GRB_Names.index:\n",
    "        #print(burst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fd1c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRB_Names = pd.read_table(\"summary/Basic_BATSE_new.dat\", sep=\"\\s+\", comment='#', header=None, usecols=[0,1,2],index_col=0)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(GRB_Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4a50ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_url_paths(url, params={}):\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.ok:\n",
    "        response_text = response.text\n",
    "    else:\n",
    "        return response.raise_for_status()\n",
    "    soup = BeautifulSoup(response_text, 'html.parser')\n",
    "    parent = [url + node.get('href') for node in soup.find_all('a') if '20' in node.get('href')]\n",
    "    return parent\n",
    "\n",
    "url = 'https://heasarc.gsfc.nasa.gov/FTP/fermi/data/gbm/bursts/'\n",
    "years = get_url_paths(url)\n",
    "tally = 0\n",
    "'''\n",
    "for year in years:\n",
    "    print(f'Currently searching through {year}')\n",
    "    for burst in get_url_paths(year):\n",
    "        tally += 1\n",
    "        has_file = False\n",
    "        for file in get_url_paths(burst+'/current/'):\n",
    "            if 'bcat_all' in file:\n",
    "                has_file = True\n",
    "        if not has_file:\n",
    "            print(burst)\n",
    "print(tally)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d87d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_paths(url, params={}):\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.ok:\n",
    "        response_text = response.text\n",
    "    else:\n",
    "        return response.raise_for_status()\n",
    "    soup = BeautifulSoup(response_text, 'html.parser')\n",
    "    print(soup)\n",
    "    parent = [url + node.get('href') for node in soup.find_all('a')]\n",
    "    return parent\n",
    "\n",
    "#url = 'https://heasarc.gsfc.nasa.gov/FTP/fermi/data/gbm/triggers/'\n",
    "#years = get_url_paths(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8823a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data = pd.read_csv('DataFrames/duration_data_Fermi.csv', index_col=0)\n",
    "fluence_data = pd.read_csv('DataFrames/fluence_data_Fermi.csv', index_col=0)\n",
    "print(len(duration_data))\n",
    "print(len(fluence_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb7b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data = pd.read_csv('DataFrames/duration_data_Fermi.csv', index_col=0)\n",
    "fluence_data = pd.read_csv('DataFrames/fluence_data_Fermi.csv', index_col=0)\n",
    "\n",
    "\n",
    "def normalize_lc(filename): # Normalize by fluence\n",
    "    grbname = filename[8:-4]\n",
    "    #Cut lightcurve\n",
    "    lc = pd.DataFrame(fits.open(filename)[2].data.field('NRGFLUX'))\n",
    "    lc = lc.squeeze() / float(fluence_data.loc[f'GRB{grbname}','fluence'])\n",
    "    return len(lc), lc # Return length and the normalized lightcurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59479d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_lc('Fermi/bn081229675.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46bd2d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.read_pickle('DataFrames/flux_data.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f2a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('DataFrames/fluence_data.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e807a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data = pd.read_csv('DataFrames/duration_data_Fermi.csv', index_col=0)\n",
    "grb_names = duration_data.index\n",
    "bcat_exists = 0\n",
    "version_numbers = {}\n",
    "'''\n",
    "for grb in grb_names:\n",
    "    for i in range(5):\n",
    "        if requests.head(f'https://heasarc.gsfc.nasa.gov/FTP/fermi/data/gbm/bursts/20{grb[3:5]}/bn{grb[3:]}/current/glg_bcat_all_bn{grb[3:]}_v0{i}.fit').status_code == 200:\n",
    "            bcat_exists += 1\n",
    "            version_numbers[grb] = i\n",
    "    if bcat_exists % 100 == 0:\n",
    "        print(f'{bcat_exists} files found')\n",
    "'''\n",
    "print(f'{bcat_exists} files total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c2dfcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#version_df = pd.DataFrame.from_dict(version_numbers, orient = 'index').reset_index()\n",
    "#version_df.columns = ['name', 'file version']\n",
    "#version_df = version_df.set_index('name')\n",
    "#version_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddd1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#version_df.to_csv('DataFrames/fermi_file_versions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e57f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('DataFrames/fermi_file_versions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b507834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "discarded = pd.read_table('DataFrames/discarded_bursts_Swift.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663dace",
   "metadata": {},
   "outputs": [],
   "source": [
    "discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1504bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'GRB190718A_lc.dat' in list(discarded.discarded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324b5f48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(list(discarded.discarded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9bd3f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary.fluence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc3f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('DataFrames/fluence_data.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data = pd.read_pickle('DataFrames/duration_data.dat')\n",
    "classification = pd.read_csv('DataFrames/classification_Swift.txt')\n",
    "group = classification.groupby(classification.type)\n",
    "short = group.get_group('S')\n",
    "long = group.get_group('L')\n",
    "plt.hist(np.log10(duration_data.loc[short.GRBname,'T90']), range = (-3,3), bins = 25, color = 'C1', edgecolor = 'C1', alpha = 0.5)\n",
    "plt.hist(np.log10(duration_data.loc[long.GRBname,'T90']), range = (-3,3), bins = 25, color = 'C4', edgecolor = 'C4', alpha = 0.5)\n",
    "plt.xlabel('log$T_{90}$', size = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a71ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data = pd.read_csv('DataFrames/duration_data_Fermi.csv').set_index('name')\n",
    "classification = pd.read_csv('DataFrames/classification_Fermi.txt')\n",
    "group = classification.groupby(classification.type)\n",
    "short = group.get_group('S')\n",
    "long = group.get_group('L')\n",
    "plt.hist(np.log10(duration_data.loc[short.GRBname,'T90']), range = (-3,3), bins = 25, color = 'C1', edgecolor = 'C1', alpha = 0.5)\n",
    "plt.hist(np.log10(duration_data.loc[long.GRBname,'T90']), range = (-3,3), bins = 25, color = 'C4', edgecolor = 'C4', alpha = 0.5)\n",
    "plt.xlabel('log$T_{90}$', size = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c6876",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data = pd.read_pickle('DataFrames/duration_data_BATSE.dat')\n",
    "classification = pd.read_csv('DataFrames/classification_BATSE.txt')\n",
    "group = classification.groupby(classification.type)\n",
    "short = group.get_group('S').loc[:,'GRBname']\n",
    "long = group.get_group('L').loc[:,'GRBname']\n",
    "plt.hist(np.log10(duration_data.loc[short,'T90']), bins = 25, color = 'C1', edgecolor = 'C1', alpha = 0.5)\n",
    "plt.hist(np.log10(duration_data.loc[long,'T90']), bins = 25, color = 'C4', edgecolor = 'C4', alpha = 0.5)\n",
    "plt.xlabel('log$T_{90}$', size = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a38a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data = pd.read_pickle('DataFrames/duration_data_BATSE.dat')\n",
    "plt.hist(np.log10(duration_data.loc[:5585,'T90']), bins = 20, color = 'C1', edgecolor = 'C1', alpha = 0.5)\n",
    "plt.xlabel('log$T_{90}$', size = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60da965f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "duration_data = pd.read_pickle('DataFrames/duration_data_BATSE.dat')\n",
    "\n",
    "fig, axs = plt.subplots(3,figsize=(8,12),constrained_layout=True)\n",
    "#figure out how to do logarithmic ticks\n",
    "plt.xlabel('log$T_{90}$',size=14)\n",
    "plt.ylabel('Count',size=14)\n",
    "axs[0].set_title('Current Catalog (2037 bursts)',size=16)\n",
    "axs[0].hist(np.log10(duration_data.loc[:,'T90']), range = (-2,3), bins = 25, color = 'C7', edgecolor = 'C7', alpha = 0.5)\n",
    "axs[1].set_title('4B Catalog (1231 bursts)',size=16)\n",
    "axs[1].hist(np.log10(duration_data.loc[:5585,'T90']), range = (-2,3), bins = 25, color = 'C7', edgecolor = 'C7', alpha = 0.5)\n",
    "axs[2].set_title('Post-4B Catalog (806 bursts)',size=16)\n",
    "axs[2].hist(np.log10(duration_data.loc[5589:,'T90']), range = (-2,3), bins = 25, color = 'C7', edgecolor = 'C7', alpha = 0.5)\n",
    "#plt.savefig('batse_duration_comparison.jpg',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d51ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data = pd.read_pickle('DataFrames/duration_data_BATSE.dat')\n",
    "classification = pd.read_csv('DataFrames/classification_BATSE_Short.txt')\n",
    "classification.GRBname = classification.GRBname.str[3:].astype('int')\n",
    "duration_data = duration_data[duration_data.index.isin(classification.GRBname.tolist())]\n",
    "display(duration_data)\n",
    "display(classification)\n",
    "group = classification.groupby(classification.type)\n",
    "short = group.get_group('S').loc[:,'GRBname']\n",
    "long = group.get_group('L').loc[:,'GRBname']\n",
    "duration_data_s = duration_data.loc[short].reindex_like(duration_data).dropna(subset=['T90'])\n",
    "duration_data_l = duration_data.loc[long].reindex_like(duration_data).dropna(subset=['T90'])\n",
    "fig, axs = plt.subplots(3,figsize=(8,12),constrained_layout=True)\n",
    "#figure out how to do logarithmic ticks\n",
    "plt.xlabel('log$T_{90}$',size=14)\n",
    "plt.ylabel('Count',size=14)\n",
    "axs[0].set_title('Current Catalog (1911 bursts)',size=16)\n",
    "axs[0].hist(np.log10(duration_data_s.loc[:,'T90']), range = (-2,3), bins = 25, color = 'C1', edgecolor = 'C1', alpha = 0.5)\n",
    "axs[0].hist(np.log10(duration_data_l.loc[:,'T90']), range = (-2,3), bins = 25, color = 'C2', edgecolor = 'C2', alpha = 0.5)\n",
    "axs[1].set_title('4B Catalog (1152 bursts)',size=16)\n",
    "axs[1].hist(np.log10(duration_data_s.loc[:5585,'T90']), range = (-2,3), bins = 25, color = 'C1', edgecolor = 'C1', alpha = 0.5)\n",
    "axs[1].hist(np.log10(duration_data_l.loc[:5585,'T90']), range = (-2,3), bins = 25, color = 'C2', edgecolor = 'C2', alpha = 0.5)\n",
    "axs[2].set_title('Post-4B Catalog (759 bursts)',size=16)\n",
    "axs[2].hist(np.log10(duration_data_s.loc[5589:,'T90']), range = (-2,3), bins = 25, color = 'C1', edgecolor = 'C1', alpha = 0.5)\n",
    "axs[2].hist(np.log10(duration_data_l.loc[5589:,'T90']), range = (-2,3), bins = 25, color = 'C2', edgecolor = 'C2', alpha = 0.5)\n",
    "#plt.savefig('batse_duration_comparison_2.jpg',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a086e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ad483",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data_s.size/5+duration_data_l.size/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d11ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data_s.loc[:5585].size/5+duration_data_l.loc[:5585].size/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f732c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data_s.loc[5589:].size/5+duration_data_l.loc[5589:].size/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ddbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data.loc[2464]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1896abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data.loc[:5585].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6982b9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data.loc[5589:].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cfde74",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_fft_dataset = pd.read_pickle('non_fft_dataset_BATSE.dat')\n",
    "classification = pd.read_csv('DataFrames/classification_BATSE.txt', index_col = 0)\n",
    "short = classification.groupby(classification.type).get_group('S')\n",
    "print(short)\n",
    "#print(short.index)\n",
    "#print('GRB107' in short.index)#.tolist())\n",
    "#non_fft_dataset = non_fft_dataset.loc[short.index]\n",
    "#non_fft_dataset = non_fft_dataset.loc[:, (non_fft_dataset != 0).any(axis=0)]\n",
    "#non_fft_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e895d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "skymap = pd.read_pickle('DataFrames/skymap_data_BATSE.dat')\n",
    "classification = pd.read_csv('DataFrames/classification_BATSE.txt', index_col=0)\n",
    "#classification.index = classification.index.str.slice(3).astype(int)\n",
    "#df = pd.concat([skymap, classification], axis=1).dropna()\n",
    "#classification.drop(classification.loc[classification.index.isin(df.index)].index)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd90fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.replace({'L': 'C4', 'S': 'C1'})\n",
    "\n",
    "xarr = np.array(data.iloc[:,0])\n",
    "yarr = np.array(data.iloc[:,1])\n",
    "eq = SkyCoord(xarr[:], yarr[:], frame='galactic', unit=u.deg)\n",
    "gal = eq.galactic\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.subplot(111, projection='aitoff')\n",
    "plt.grid(True)\n",
    "plt.scatter(gal.l.wrap_at('180d').radian, gal.b.radian, c = data.iloc[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c51ceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = pd.read_csv('LC/GRB5989.csv', skiprows=1, header=None, sep='\\s+')\n",
    "header = pd.Series(data=file.loc[0].values, index=['trig#', 'npts', 'nlasc', '1preb'], dtype='int64')\n",
    "display(header)\n",
    "display(duration_data.loc[5989])\n",
    "rates = file.drop(0).reset_index(drop=True)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbcad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates[(header['nlasc']-10):(header['nlasc']+5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fac3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data = pd.read_pickle(\"DataFrames/duration_data_BATSE.dat\")\n",
    "fluence_data = pd.read_pickle(\"DataFrames/fluence_data_BATSE.dat\")\n",
    "\n",
    "def cut_norm_lc(filename): #Prepare single light curve, cut to T90 and normalize by fluence\n",
    "    trigger = int(filename[6:-4])\n",
    "    #Cut lightcurve\n",
    "    file = pd.read_csv(filename, skiprows=1, header=None, sep='\\s+')\n",
    "    header = pd.Series(data=file.loc[0].values, index=['trig#', 'npts', 'nlasc', '1preb'], dtype='int64')\n",
    "    trig_time = header['nlasc'] + 32\n",
    "    lc = file.drop(0).reset_index(drop=True)\n",
    "    lc = lc.loc[(trig_time + duration_data.loc[trigger,'start_T90']/0.064):(trig_time + (duration_data.loc[trigger,'start_T90'] + duration_data.loc[trigger,'T90'])/0.064 - 1)]\n",
    "    lc.reset_index(drop=True,inplace=True)\n",
    "    lc = lc.iloc[:,[0,1,2,3]] / float(fluence_data.loc[trigger,'fluence'])\n",
    "    return len(lc), lc # Return length and the cut lightcurve\n",
    "\n",
    "filename = 'LC/GRB107.csv'\n",
    "display(duration_data.loc[int(filename[6:-4])])\n",
    "display(fluence_data.loc[int(filename[6:-4]), 'fluence'])\n",
    "length, lc = cut_norm_lc(filename)\n",
    "print(lc)\n",
    "plt.plot(lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc2d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluence_data = pd.read_pickle(\"DataFrames/fluence_data_BATSE.dat\")\n",
    "duration_data = pd.read_pickle(\"DataFrames/duration_data_BATSE.dat\")\n",
    "data_problems = pd.read_pickle(\"DataFrames/data_problems_BATSE.dat\")\n",
    "\n",
    "def cut_norm_lc(filename): #Prepare single light curve, cut to T90 and normalize by fluence\n",
    "    trigger = int(filename[9:-5])\n",
    "    #Cut lightcurve\n",
    "    lc = pd.concat([pd.DataFrame(fits.open(filename)[2].data.field('TIMES')), pd.DataFrame(fits.open(filename)[2].data.field('RATES'))], axis = 1, ignore_index = True)\n",
    "    #if str(trigger) in data_problems.index:\n",
    "    #    lc.loc[data_problems.loc[str(trigger),'location']] /= 100\n",
    "    #if f'GRB{str(trigger)}' in list(outliers):\n",
    "        #lc = lc.drop(index=data_problems.loc[str(trigger),'location'])\n",
    "    print(lc)\n",
    "    lc = lc.loc[lc.loc[:,0].apply(lambda x: duration_data.loc[trigger,'start_T90'] - 0.064 < x and x <= (duration_data.loc[trigger,'start_T90'] + duration_data.loc[trigger,'T90']))]\n",
    "    #lc = lc[lc[1] - lc[0] <= 0.006]\n",
    "    lc.reset_index(drop=True,inplace=True)\n",
    "    #lc = lc.iloc[:,[1,2,3,4]] / float(fluence_data.loc[trigger,'fluence'])\n",
    "    lc.iloc[:,0] = pd.to_timedelta(pd.Series(lc.iloc[:,0]), unit = 's')\n",
    "    lc.iloc[:,1] = pd.to_timedelta(pd.Series(lc.iloc[:,1]), unit = 's')\n",
    "    #print(lc.iloc[:,1] - lc.iloc[:,0])\n",
    "    lc = lc.resample('64ms', on=0).mean().pad()\n",
    "    lc.reset_index(drop=True,inplace=True)\n",
    "    lc = lc.loc[:,[2,3,4,5]] / float(fluence_data.loc[trigger,'fluence'])\n",
    "    return len(lc), lc # Return length and the cut lightcurve\n",
    "trig = 107\n",
    "print(duration_data.loc[trig,'T90']/0.064)\n",
    "print(cut_norm_lc(f'BATSE/GRB{trig}.fits'))\n",
    "plt.plot(cut_norm_lc(f'BATSE/GRB{trig}.fits')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluence_data = pd.read_pickle(\"DataFrames/fluence_data_BATSE.dat\")\n",
    "duration_data = pd.read_pickle(\"DataFrames/duration_data_BATSE.dat\")\n",
    "from scipy.signal import lfilter\n",
    "def cut_norm_lc(filename): #Prepare single light curve, cut to T90 and normalize by fluence\n",
    "    trigger = int(filename[6:-4])\n",
    "    #Cut lightcurve\n",
    "    file = pd.read_csv(filename, skiprows=1, header=None, sep='\\s+')\n",
    "    times = pd.DataFrame(fits.open(f'BATSE/GRB{trigger}.fits')[2].data.field('TIMES'))\n",
    "    header = pd.Series(data=file.loc[0].values, index=['trig#', 'npts', 'nlasc', '1preb'], dtype='int64')\n",
    "    trig_time = header['nlasc'] + 32\n",
    "    lc = file.drop(0).reset_index(drop=True)\n",
    "    for i in range(4):\n",
    "        b1 = lc.iloc[0,i]\n",
    "        b2 = lc.iloc[-1,i]\n",
    "        lc.iloc[:,i] = lc.iloc[:,i] - [b1 + (b2-b1)/(len(lc)-1)*i for i in range(len(lc))]\n",
    "    start = trig_time + max([times.min().min(), duration_data.loc[trigger,'start_T90']])/0.064\n",
    "    end = trig_time + min([times.max().max(), duration_data.loc[trigger,'start_T90']+duration_data.loc[trigger,'T90']])/0.064 - 1\n",
    "    #lc = lc.loc[start:end]\n",
    "    lc = lc.loc[(trig_time + duration_data.loc[trigger,'start_T90']/0.064):(trig_time + (duration_data.loc[trigger,'start_T90'] + duration_data.loc[trigger,'T90'])/0.064 - 1)]\n",
    "    lc.reset_index(drop=True,inplace=True)\n",
    "    lc = lc.iloc[:,[0,1,2,3]] / float(fluence_data.loc[trigger,'fluence'])\n",
    "    #for i in range(4):\n",
    "        #lc.iloc[:,i] -= lc.iloc[:,i].min()\n",
    "    return len(lc), lc # Return length and the cut lightcurve\n",
    "\n",
    "filename = 'LC/GRB5508.csv'\n",
    "display(duration_data.loc[int(filename[6:-4])])\n",
    "display(fluence_data.loc[int(filename[6:-4]), 'fluence'])\n",
    "length, lc = cut_norm_lc(filename)\n",
    "#print(lc)\n",
    "plt.plot(lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a7481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(abs(np.fft.rfft(pd.read_pickle('non_fft_dataset.dat'))))\n",
    "plt.show()\n",
    "plt.plot(abs(np.fft.rfft(pd.read_pickle('non_fft_dataset_Fermi.dat'))))\n",
    "plt.show()\n",
    "plt.plot(abs(np.fft.rfft(pd.read_pickle('non_fft_dataset_BATSE_LC.dat'))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f59dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "plt.plot(abs(np.fft.rfft(StandardScaler().fit_transform(pd.read_pickle('non_fft_dataset_BATSE_LC.dat')))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = abs(np.fft.rfft(pd.read_pickle('non_fft_dataset.dat')))\n",
    "print(df1)\n",
    "df2 = abs(np.fft.rfft(pd.read_pickle('non_fft_dataset_Fermi.dat')))\n",
    "print(df2)\n",
    "df3 = abs(np.fft.rfft(pd.read_pickle('non_fft_dataset_BATSE_LC.dat')))\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c515bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_max = 0\n",
    "x_i = 0\n",
    "for i in range(len(df1)):\n",
    "    plt.plot(df1[i])\n",
    "plt.show()\n",
    "for i in range(len(df2)):\n",
    "    if max(df2[i]) > x_max:\n",
    "        x_max = max(df2[i])\n",
    "        x_i = i\n",
    "    plt.plot(df2[i])\n",
    "plt.show()\n",
    "print(x_i)\n",
    "plt.plot(df2[x_i])\n",
    "plt.show()\n",
    "for i in range(len(df3)):\n",
    "    plt.plot(df3[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00930d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('non_fft_dataset_Fermi.dat').iloc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515895ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data = pd.read_pickle('DataFrames/duration_data.dat')\n",
    "fluence_data = pd.read_pickle('DataFrames/fluence_data.dat')\n",
    "\n",
    "def cut_norm_lc(filename): #Prepare single light curve, cut to T100 and normalize by fluence\n",
    "    grbname = filename[12:-7]\n",
    "    #Cut lightcurve\n",
    "    lc = pd.read_csv(filename, sep = ' ', header = None)\n",
    "    lc = lc.loc[:, [0, 1, 3, 5, 7]]\n",
    "    lc = lc.loc[lc.loc[:,0].apply(lambda x: duration_data.T100_start[grbname] <= x and x <= duration_data.T100_end[grbname])]\n",
    "    lc.reset_index(drop=True,inplace=True)\n",
    "    lc = lc.iloc[:,[1,2,3,4]] / float(fluence_data.loc[grbname, 'fluence'])\n",
    "    return len(lc), lc # Return length and the cut lightcurve\n",
    "\n",
    "for i in range(100):\n",
    "    name = pd.read_pickle('non_fft_dataset.dat').index[i]\n",
    "    print(name)\n",
    "    plt.plot(df1[i])\n",
    "    plt.show()\n",
    "    plt.plot(cut_norm_lc(f'LightCurves/{name}_lc.dat')[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1804db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluence_data = pd.read_csv('DataFrames/fluence_data_Fermi.csv', index_col=0)\n",
    "def normalize_lc(filename): # Normalize by fluence\n",
    "    grbname = filename[8:-4]\n",
    "    #Cut lightcurve\n",
    "    lc = pd.DataFrame(fits.open(filename)[2].data.field('NRGFLUX'))\n",
    "    lc = lc.squeeze() / float(fluence_data.loc[f'GRB{grbname}','fluence'])\n",
    "    return len(lc), lc # Return length and the normalized lightcurve\n",
    "\n",
    "for i in range(100):\n",
    "    name = pd.read_pickle('non_fft_dataset_Fermi.dat').index[i][3:]\n",
    "    print('GRB'+name)\n",
    "    plt.plot(df2[i])\n",
    "    plt.show()\n",
    "    plt.plot(normalize_lc(f'Fermi/bn{name}.fit')[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ad160",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data = pd.read_pickle(\"DataFrames/duration_data_BATSE.dat\")\n",
    "fluence_data = pd.read_pickle(\"DataFrames/fluence_data_BATSE.dat\")\n",
    "\n",
    "def cut_norm_lc(filename): #Prepare single light curve, cut to T90 and normalize by fluence\n",
    "    trigger = int(filename[6:-4])\n",
    "    #Cut lightcurve\n",
    "    file = pd.read_csv(filename, skiprows=1, header=None, sep='\\s+')\n",
    "    times = pd.DataFrame(fits.open(f'BATSE/GRB{trigger}.fits')[2].data.field('TIMES'))\n",
    "    header = pd.Series(data=file.loc[0].values, index=['trig#', 'npts', 'nlasc', '1preb'], dtype='int64')\n",
    "    trig_time = header['nlasc'] + 32\n",
    "    lc = file.drop(0).reset_index(drop=True)\n",
    "    for i in range(4):\n",
    "        b1 = lc.iloc[0,i]\n",
    "        b2 = lc.iloc[-1,i]\n",
    "        lc.iloc[:,i] = lc.iloc[:,i] - [b1 + (b2-b1)/(len(lc)-1)*i for i in range(len(lc))]\n",
    "    start = trig_time + max([times.min().min(), duration_data.loc[trigger,'start_T90']])/0.064\n",
    "    end = trig_time + min([times.max().max(), duration_data.loc[trigger,'start_T90']+duration_data.loc[trigger,'T90']])/0.064 - 1\n",
    "    lc = lc.loc[start:end]\n",
    "    #lc = lc.loc[(trig_time + duration_data.loc[trigger,'start_T90']/0.064):(trig_time + (duration_data.loc[trigger,'start_T90'] + duration_data.loc[trigger,'T90'])/0.064 - 1)]\n",
    "    lc.reset_index(drop=True,inplace=True)\n",
    "    lc = lc.iloc[:,[0,1,2,3]] / float(fluence_data.loc[trigger,'fluence'])\n",
    "    return len(lc), lc # Return length and the cut lightcurve\n",
    "\n",
    "\n",
    "for i in range(1500,1600):\n",
    "    name = pd.read_pickle('non_fft_dataset_BATSE_LC.dat').index[i]\n",
    "    print('GRB'+name)\n",
    "    plt.plot(df3[i])\n",
    "    plt.show()\n",
    "    plt.plot(cut_norm_lc(f'LC/GRB{name}.csv')[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8269114f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "duration_data = pd.read_pickle(\"DataFrames/duration_data_BATSE.dat\")\n",
    "fluence_data = pd.read_pickle(\"DataFrames/fluence_data_BATSE.dat\")\n",
    "from math import ceil, floor\n",
    "def cut_norm_lc(filename): #Prepare single light curve, cut to T90 and normalize by fluence\n",
    "    trigger = int(filename[6:-4])\n",
    "    #Cut lightcurve\n",
    "    file = pd.read_csv(filename, skiprows=1, header=None, sep='\\s+')\n",
    "    times = pd.DataFrame(fits.open(f'BATSE/GRB{trigger}.fits')[2].data.field('TIMES'))\n",
    "    header = pd.Series(data=file.loc[0].values, index=['trig#', 'npts', 'nlasc', '1preb'], dtype='int64')\n",
    "    trig_time = header['nlasc'] + 32\n",
    "    print(trig_time)\n",
    "    lc = file.drop(0).reset_index(drop=True)\n",
    "    for i in range(4):\n",
    "        b1 = lc.iloc[0,i]\n",
    "        b2 = lc.iloc[-1,i]\n",
    "        lc.iloc[:,i] = lc.iloc[:,i] - [b1 + (b2-b1)/(len(lc)-1)*i for i in range(len(lc))]\n",
    "        #lc.iloc[:,i] -= b2\n",
    "    print(ceil(min([times.max().max(), duration_data.loc[trigger,'start_T90']+duration_data.loc[trigger,'T90']])/0.064))\n",
    "    start = trig_time + floor(max([times.min().min(), duration_data.loc[trigger,'start_T90']])/0.064)\n",
    "    end = trig_time + ceil(min([times.max().max(), duration_data.loc[trigger,'start_T90']+duration_data.loc[trigger,'T90']])/0.064) - 1\n",
    "    lc = lc.loc[start:end]\n",
    "    print(lc)\n",
    "    #lc = lc.loc[(trig_time + duration_data.loc[trigger,'start_T90']/0.064 - 1):(trig_time + (duration_data.loc[trigger,'start_T90'] + duration_data.loc[trigger,'T90'])/0.064)]\n",
    "    lc.reset_index(drop=True,inplace=True)\n",
    "    #lc = lc.iloc[:,[0,1,2,3]] / float(fluence_data.loc[trigger,'fluence'])\n",
    "    return len(lc), lc # Return length and the cut lightcurve\n",
    "\n",
    "i = -1\n",
    "for x in pd.read_pickle('non_fft_dataset_BATSE_LC.dat').index:\n",
    "    i += 1\n",
    "    if x == '491':\n",
    "        break\n",
    "        \n",
    "name = pd.read_pickle('non_fft_dataset_BATSE_LC.dat').index[i]\n",
    "print('GRB'+name)\n",
    "print(duration_data.loc[int(name)])\n",
    "plt.plot(df3[i])\n",
    "plt.show()\n",
    "plt.plot(cut_norm_lc(f'LC/GRB{name}.csv')[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c03f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'LC/GRB1009.csv'\n",
    "trigger = int(filename[6:-4])\n",
    "display(duration_data.loc[trigger])\n",
    "file = pd.read_csv(filename, skiprows=1, header=None, sep='\\s+')\n",
    "header = pd.Series(data=file.loc[0].values, index=['trig#', 'npts', 'nlasc', '1preb'], dtype='int64')\n",
    "trig_time = header['nlasc'] + 32\n",
    "lc = file.drop(0).reset_index(drop=True)\n",
    "lc = lc.iloc[:,[0,1,2,3]] / float(fluence_data.loc[trigger,'fluence'])\n",
    "plt.plot(lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad683ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('DataFrames/classification_BATSE.txt',index_col=0)\n",
    "df1.index = df1.index.astype(str)\n",
    "print(df1.index)\n",
    "df2 = pd.read_pickle('non_fft_dataset_BATSE_LC.dat')\n",
    "print(df2.index)\n",
    "df = pd.concat((df1,df2),axis=1)\n",
    "#df[6645]\n",
    "print(df[df.isna().any(1)])\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a369576",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger = 148\n",
    "duration_data = pd.read_pickle(\"DataFrames/duration_data_BATSE.dat\")\n",
    "display(duration_data.loc[trigger])\n",
    "trigger_time = header['nlasc'] + 32\n",
    "#rates = rates.loc[rates.reset_index().loc.apply(lambda x: trigger_time + duration_data.loc[trigger,'start_T90']/0.064 <= x and x <= trigger_time + (duration_data.loc[trigger,'start_T90'] + duration_data.loc[trigger,'T90'])/0.064)]\n",
    "duration_data.loc[trigger]\n",
    "rates.loc[(trigger_time + duration_data.loc[trigger,'start_T90']/0.064 - 3):(trigger_time + (duration_data.loc[trigger,'start_T90'] + duration_data.loc[trigger,'T90'])/0.064 - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1604c417",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data = pd.read_pickle(\"DataFrames/duration_data_BATSE.dat\")\n",
    "fluence_data = pd.read_pickle(\"DataFrames/fluence_data_BATSE.dat\")\n",
    "\n",
    "def cut_norm_lc(filename): #Prepare single light curve, cut to T90 and normalize by fluence\n",
    "    trigger = int(filename[6:-4])\n",
    "    #Cut lightcurve\n",
    "    file = pd.read_csv(filename, skiprows=1, header=None, sep='\\s+')\n",
    "    header = pd.Series(data=file.loc[0].values, index=['trig#', 'npts', 'nlasc', '1preb'], dtype='int64')\n",
    "    trig_time = header['nlasc'] + 32\n",
    "    lc = file.drop(0).reset_index(drop=True)\n",
    "    lc = lc.loc[(trig_time + duration_data.loc[trigger,'start_T90']/0.064):(trig_time + (duration_data.loc[trigger,'start_T90'] + duration_data.loc[trigger,'T90'])/0.064 - 1)]\n",
    "    lc.reset_index(drop=True,inplace=True)\n",
    "    lc = lc.iloc[:,[0,1,2,3]] / float(fluence_data.loc[trigger,'fluence'])\n",
    "    return len(lc), lc # Return length and the cut lightcurve\n",
    "\n",
    "cut_norm_lc('LC/GRB105.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab0bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(duration_data.loc[5585:,'T90']), bins = 50, color = 'C0', edgecolor = 'C0', alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d441d278",
   "metadata": {},
   "outputs": [],
   "source": [
    "short = pd.read_csv('DataFrames/classification_BATSE_Short.txt', index_col=0)\n",
    "#short.index = short.index.str.slice(3).astype(int)\n",
    "print(short.index)\n",
    "#print(pd.read_csv(\"embedding_TSNE_BATSE_Short.csv\", header = None, index_col = 0).index)\n",
    "#short.index.isin(pd.read_csv(\"embedding_TSNE_BATSE_Short.csv\", header = None, index_col = 0).index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e277415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#short.loc[pd.read_csv(\"embedding_TSNE_BATSE_Short.csv\", header = None, index_col = 0).index]\n",
    "#print(pd.read_csv(\"embedding_TSNE_BATSE_Short.csv\", header = None, index_col = 0).index)\n",
    "pd.concat([short, pd.read_csv(\"embedding_TSNE_BATSE_Short.csv\", header = None, index_col = 0)], axis=1).dropna(subset=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318085e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster as cluster\n",
    "prediction = cluster.SpectralClustering(2).fit_predict(abs(np.fft.rfft(pd.read_pickle('non_fft_dataset.dat'))))\n",
    "print(prediction)\n",
    "t1 = 0\n",
    "t2 = 0\n",
    "for i in prediction:\n",
    "    print(i)\n",
    "    if(i == 0):\n",
    "        t1 += 1\n",
    "    else:\n",
    "        t2 += 1\n",
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43baa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = pd.read_csv(\"embedding_TSNE_20.csv\", header = None).set_index(0)\n",
    "plt.scatter(emb[1], emb[2], c=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bf6961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'Dropbox/jackson/maps_0524/tsne_maps/'\n",
    "#path = 'Dropbox/jackson/tsne_maps_swift/'\n",
    "namedict = pd.read_pickle('DataFrames/classification.dat').reset_index().to_dict()['GRBname']\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.Dark2.colors)\n",
    "for file in os.listdir(path):\n",
    "    emb = pd.read_csv((path+file), header = None).replace({0:namedict}).set_index(0)\n",
    "    plt.scatter(emb[1], emb[2], s=10, c=pd.read_pickle('DataFrames/classification.dat').replace({'L': 'C2', 'S': 'C1'}).type.reindex_like(emb))\n",
    "    plt.tick_params('both',bottom=False,top=False,left=False,right=False,labelbottom=False,labelleft=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af8af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'umap_maps/'\n",
    "classification = pd.read_pickle('DataFrames/classification.dat')\n",
    "classification['GRB090813'] = 'S'\n",
    "namedict = classification.reset_index().to_dict()['GRBname']\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.Dark2.colors)\n",
    "for file in os.listdir(path):\n",
    "    emb = pd.read_csv((path+file), header = None).replace({0:namedict}).set_index(0)\n",
    "    plt.scatter(emb[1], emb[2], s=10, c=classification.replace({'L': 'C2', 'S': 'C1'}).type.reindex_like(emb))\n",
    "    plt.tick_params('both',bottom=False,top=False,left=False,right=False,labelbottom=False,labelleft=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49a53b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = 'tsne_maps/'\n",
    "for file in os.listdir(path):\n",
    "    emb = pd.read_csv((path+file), header = None).set_index(0)\n",
    "    plt.scatter(emb[1], emb[2], c=emb[5])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d26e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'umap_maps/'\n",
    "for file in os.listdir(path):\n",
    "    emb = pd.read_csv((path+file), header = None).set_index(0)\n",
    "    plt.scatter(emb[1], emb[2], c=emb[4])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5559f46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_pickle('DataFrames/classification.dat').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15578f1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hardness_data = pd.read_pickle('DataFrames/hardness_data.dat')\n",
    "classification = pd.read_csv('DataFrames/classification_Swift.txt')\n",
    "group = classification.groupby(classification.type)\n",
    "short = group.get_group('S')\n",
    "long = group.get_group('L')\n",
    "plt.hist(np.log10(hardness_data.loc[short.GRBname,'hardness']), range = (-1,1), bins = 25, color = 'C1', edgecolor = 'C1', alpha = 0.5)\n",
    "plt.hist(np.log10(hardness_data.loc[long.GRBname,'hardness']), range = (-1,1), bins = 25, color = 'C2', edgecolor = 'C2', alpha = 0.5)\n",
    "plt.xlabel('$s(50-100keV)/s(25-50keV)$', size = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a03e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hardness_data = pd.read_pickle('DataFrames/hardness_data_BATSE.dat')\n",
    "classification = pd.read_csv('DataFrames/classification_BATSE.txt')\n",
    "group = classification.groupby(classification.type)\n",
    "short = group.get_group('S')\n",
    "long = group.get_group('L')\n",
    "plt.hist(np.log10(hardness_data.loc[short.GRBname,'hardness']), range = (-1,1), bins = 25, color = 'C1', edgecolor = 'C1', alpha = 0.5)\n",
    "plt.hist(np.log10(hardness_data.loc[long.GRBname,'hardness']), range = (-1,1), bins = 25, color = 'C2', edgecolor = 'C2', alpha = 0.5)\n",
    "plt.xlabel('$s(100-300keV)/s(50-100keV)$', size = 12)\n",
    "#plt.xlabel('$s(50-100keV)/s(20-50keV)$', size = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad35467",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = pd.read_csv('DataFrames/intersection_Swift_Fermi.csv')\n",
    "Swift = pd.read_csv('DataFrames/classification_Swift.txt')\n",
    "Swift = Swift[Swift.isin(intersection.Swift.tolist()).GRBname].reset_index(drop=True)\n",
    "display(Swift)\n",
    "Fermi = pd.read_csv('DataFrames/classification_Fermi.txt')\n",
    "Fermi = Fermi[Fermi.isin(intersection.Fermi.tolist()).GRBname].reset_index(drop=True)\n",
    "display(Fermi)\n",
    "classification = pd.concat([Swift,Fermi], axis=1)\n",
    "classification = classification[classification.iloc[:,1] != classification.iloc[:,3]].reset_index(drop=True)\n",
    "classification.columns = ['Swift', 'type', 'Fermi', 'type']\n",
    "display(classification)\n",
    "classification.set_index('Swift').to_csv('DataFrames/mismatching_classifications.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1904f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806ceb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = pd.read_csv(\"embedding_TSNE_20.csv\", header = None).set_index(0)\n",
    "source = ColumnDataSource({'names': emb.index.tolist(), 'x': emb[1].tolist(), 'y': emb[2].tolist()})#, 'color': None})\n",
    "plot = figure(title='t-SNE projection of the BATSE catalog of GRBs', plot_width=800, plot_height=600, tools=\"pan,wheel_zoom,box_zoom,lasso_select,reset\")\n",
    "plot.add_tools(HoverTool(tooltips=\"\"\"\n",
    "<div>\n",
    "    <div>\n",
    "        <span><pre>@names</pre></span>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"))\n",
    "#color_bar = ColorBar(color_mapper=color_mapper, label_standoff=8)\n",
    "#plot.add_layout(color_bar, 'above')\n",
    "plot.scatter(x = 'x', y = 'y', source = source)#, color={'field': 'color', 'transform': color_mapper})\n",
    "multi_choice = MultiChoice(options=emb.index.tolist())\n",
    "update_highlights = CustomJS(args=dict(source=source), code=\"\"\"\n",
    "    source.selected['indices'] = []\n",
    "    for(var i = 0; i < source.get_length(); i++) {\n",
    "        //console.log(i, source.data['names'][i], cb_obj.value)\n",
    "        if (cb_obj.value.includes(source.data['names'][i])) {\n",
    "            source.selected['indices'].push(i)\n",
    "        }\n",
    "    }\n",
    "    source.change.emit()\n",
    "\"\"\")\n",
    "selected_indices = []\n",
    "multi_choice.js_on_change('value', update_highlights)\n",
    "callback = CustomJS(args=dict(source=source), code=\"\"\"\n",
    "    //console.log('Running CustomJS callback now.');\n",
    "    var indices = source.selected.indices;\n",
    "    var kernel = IPython.notebook.kernel;\n",
    "    kernel.execute(\"selected_indices = \" + indices)\n",
    "\"\"\")\n",
    "plot.js_on_event('selectiongeometry', callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ebea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(column(multi_choice,plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd8026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = emb.reset_index().isin(emb.iloc[list(selected_indices)].index)[0].replace({False: 'L', True: 'S'})\n",
    "df = pd.concat([pd.Series(emb.index), selected], axis = 1, ignore_index = True).rename({0: 'GRBname', 1: 'type'}, axis=1).set_index('GRBname')\n",
    "print(df.loc[df.type=='S'])\n",
    "print(df.loc[df.type=='L'])\n",
    "print(len(df))\n",
    "df = df.loc[df.type=='S'].replace({'S':'C0'})\n",
    "df\n",
    "#df.to_csv('DataFrames/third_group_Swift.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633e2798",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = pd.read_csv(\"embedding_TSNE.csv\", header = None).set_index(0)\n",
    "emb[3] = DBSCAN(eps=7).fit_predict(emb.loc[:,[1,2]])\n",
    "#emb[3] = emb[3].map({0:'C2',1:'C1'})\n",
    "plt.scatter(emb[1], emb[2], s=5, c=emb[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515c2c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hardness_data = pd.read_pickle('DataFrames/hardness_data_BATSE.dat')\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(hardness_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa4de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = pd.concat([pd.read_csv('DataFrames/classification_BATSE.txt', index_col=0), pd.read_csv(\"embedding_TSNE_BATSE.csv\", header = None, index_col = 0)], axis=1).dropna(subset=[1])\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd349d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_fft_dataset = pd.read_pickle('non_fft_dataset_BATSE_LC.dat')\n",
    "non_fft_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecb2c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = pd.read_csv('embedding_TSNE_BATSE.csv', header=None, index_col=0)\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeac2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack((non_fft_dataset.index, emb.loc[:,1], emb.loc[:,2])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a3a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Dropbox/jackson/tsne_maps_fermi/'\n",
    "counts = {grb:[0,0] for grb in pd.read_pickle('non_fft_dataset_Fermi.dat').index}\n",
    "#for file in os.listdir(path):\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    file = f'embedding_TSNE_Fermi{i}.csv'\n",
    "    emb = pd.read_csv(path+file,header=None,index_col=0)\n",
    "    long = int(len(emb.groupby(emb.iloc[:,2]).get_group(1)) > len(emb.groupby(emb.iloc[:,2]).get_group(0)))\n",
    "    emb.iloc[:,2] = emb.replace({long:1,1-long:0}).iloc[:,2]\n",
    "    for i in range(emb.index.size):\n",
    "        row = emb.iloc[i]\n",
    "        counts[row.name][int(row[3])] += 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a651d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(counts).T\n",
    "df[3] = df.max(axis=1)/df.sum(axis=1)\n",
    "df.columns = ['S', 'L', '%']\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca9266b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emb = pd.read_csv('Dropbox/jackson/tsne_maps_fermi/embedding_TSNE_Fermi3.csv', header=None, index_col=0)\n",
    "long = int(len(emb.groupby(emb.iloc[:,2]).get_group(1)) > len(emb.groupby(emb.iloc[:,2]).get_group(0)))\n",
    "emb.iloc[:,2] = emb.replace({long:1,1-long:0}).iloc[:,2]\n",
    "#display(emb)\n",
    "for i in range(emb.index.size):\n",
    "    row = emb.iloc[i]\n",
    "    counts[row.name][int(row[3])] += 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0f1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = pd.read_csv('Dropbox/jackson/tsne_maps_swift/embedding_TSNE_Swift6.csv', header=None, index_col=0)\n",
    "plt.scatter(emb[1],emb[2],s=5,c=emb[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a8798",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('non_fft_dataset.dat')\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a3fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.read_csv('DataFrames/classification_Swift.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df96214",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = pd.read_csv('DataFrames/classification_Swift.txt')\n",
    "df = pd.read_pickle('non_fft_dataset.dat').loc[classification.GRBname.loc[classification.type=='S']]\n",
    "df = df.loc[:, (df != 0).any(axis=0)]\n",
    "fft = np.fft.rfft(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data = pd.read_pickle(\"DataFrames/duration_data.dat\")\n",
    "emb = TSNE(verbose = 2, perplexity = 15, n_iter = 15000).fit_transform(abs(fft))\n",
    "plt.scatter(emb[:,0], emb[:,1], s=5, c=np.log10(duration_data.loc[df.index].T90), cmap='plasma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaea11d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = np.log10(duration_data.loc[df.index].T90)\n",
    "source = ColumnDataSource({'names': df.index.tolist(), 'x': emb[:,0].tolist(), 'y': emb[:,1].tolist(), 'color': color})\n",
    "color_mapper = LinearColorMapper(palette=Plasma256, low=min(color), high=max(color))\n",
    "plot = figure(title='t-SNE projection of the Swift catalog of GRBs', plot_width=800, plot_height=600, tools=\"pan,wheel_zoom,box_zoom,lasso_select,reset\")\n",
    "plot.add_tools(HoverTool(tooltips=\"\"\"\n",
    "<div>\n",
    "    <div>\n",
    "        <span><pre>@names</pre></span>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"))\n",
    "plot.scatter(x = 'x', y = 'y', source = source, color={'field': 'color', 'transform': color_mapper})\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab03318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = pd.read_csv('DataFrames/classification_Fermi.txt')\n",
    "df = pd.read_pickle('non_fft_dataset_Fermi.dat').loc[classification.GRBname.loc[classification.type=='S']]\n",
    "df = df.loc[:, (df != 0).any(axis=0)]\n",
    "fft = np.fft.rfft(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7121321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data = pd.read_pickle(\"DataFrames/duration_data_Fermi.dat\")\n",
    "emb = TSNE(verbose = 2, perplexity = 20, n_iter = 15000).fit_transform(abs(fft))\n",
    "plt.scatter(emb[:,0], emb[:,1], s=5, c=np.log10(duration_data.loc[df.index].T90), cmap='plasma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59209f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = np.log10(duration_data.loc[df.index].T90)\n",
    "source = ColumnDataSource({'names': df.index.tolist(), 'x': emb[:,0].tolist(), 'y': emb[:,1].tolist(), 'color': color})\n",
    "color_mapper = LinearColorMapper(palette=Plasma256, low=min(color), high=max(color))\n",
    "plot = figure(title='t-SNE projection of the Fermi catalog of GRBs', plot_width=800, plot_height=600, tools=\"pan,wheel_zoom,box_zoom,lasso_select,reset\")\n",
    "plot.add_tools(HoverTool(tooltips=\"\"\"\n",
    "<div>\n",
    "    <div>\n",
    "        <span><pre>@names</pre></span>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"))\n",
    "plot.scatter(x = 'x', y = 'y', source = source, color={'field': 'color', 'transform': color_mapper})\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a44436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "emb = pd.read_csv('embedding_TSNE_Fermi_20.csv', header=None, index_col=0)\n",
    "classification = pd.read_csv('DataFrames/classification_Fermi.txt')\n",
    "group = classification.groupby(classification.type)\n",
    "short = emb.loc[group.get_group('S').GRBname]\n",
    "long = emb.loc[group.get_group('L').GRBname]\n",
    "print(cdist(short,long).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_pickle('non_fft_dataset_BATSE_LC_2.dat')\n",
    "#df[~df.isin(df.dropna())]\n",
    "#df[df.eq(np.inf).any(1)]\n",
    "df = pd.read_pickle('DataFrames/fluence_data.dat')\n",
    "#df[df.astype(float)==0]\n",
    "#df[df.eq(0).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "emblist = []\n",
    "non_fft_dataset = pd.read_pickle('non_fft_dataset.dat')\n",
    "fft = np.fft.rfft(non_fft_dataset)\n",
    "warnings.filterwarnings('ignore')\n",
    "from ipynb.fs.full.config_TSNE import tsne_params\n",
    "verbose, perplexity, n_iter = tsne_params['verbose'], tsne_params['perplexity'], tsne_params['n_iter']\n",
    "for i in range(16):\n",
    "    print(f'embedding #{i+1} out of 16:')\n",
    "    emb = TSNE(verbose = verbose, perplexity = perplexity, n_iter = n_iter).fit_transform(abs(fft))\n",
    "    emblist.append(pd.DataFrame(np.vstack((emb[:,0], emb[:,1])).T, non_fft_dataset.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c14df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.config_TSNE import conf\n",
    "\n",
    "classification = pd.read_pickle('DataFrames/classification.dat')\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.Dark2.colors)\n",
    "color = classification.replace({'L': 'C2', 'S': 'C1'}).type\n",
    "\n",
    "fig = plt.figure(figsize=(8,8), tight_layout=True)\n",
    "#fig.suptitle('Swift maps with randomized orders', size=16)\n",
    "gs = fig.add_gridspec(4, 4, hspace=0, wspace=0)\n",
    "axs = gs.subplots(sharex='col', sharey='row')\n",
    "for i in range(16):\n",
    "    ax = axs[i//4][i%4]\n",
    "    emb = emblist[i]\n",
    "    ax.set(xticks=(), yticks=())\n",
    "    #ax.scatter(emb[0], emb[1], s=conf['radius'], c=conf['color'], cmap=conf['cmap'])\n",
    "    ax.scatter(emb[0], emb[1], s=2, c=color, cmap=conf['cmap'])\n",
    "fig.savefig(\"changeorder.jpg\", dpi=300)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da542e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "duration_data_s = pd.read_pickle('DataFrames/duration_data.dat')\n",
    "classification = pd.read_csv('DataFrames/classification_Swift.txt')\n",
    "group = classification.groupby(classification.type)\n",
    "swift_short = group.get_group('S')\n",
    "swift_long = group.get_group('L')\n",
    "swift_s = [d for d in duration_data_s.loc[swift_short.GRBname,'T90']]\n",
    "swift_l = [d for d in duration_data_s.loc[swift_long.GRBname,'T90']]\n",
    "\n",
    "duration_data_f = pd.read_pickle('DataFrames/duration_data_Fermi.dat')\n",
    "classification = pd.read_csv('DataFrames/classification_Fermi.txt')\n",
    "group = classification.groupby(classification.type)\n",
    "fermi_short = group.get_group('S')\n",
    "fermi_long = group.get_group('L')\n",
    "fermi_s = [d for d in duration_data_f.loc[fermi_short.GRBname,'T90']]\n",
    "fermi_l = [d for d in duration_data_f.loc[fermi_long.GRBname,'T90']]\n",
    "\n",
    "duration_data_b = pd.read_pickle('DataFrames/duration_data_BATSE.dat')\n",
    "classification = pd.read_csv('DataFrames/classification_BATSE.txt')\n",
    "group = classification.groupby(classification.type)\n",
    "batse_short = group.get_group('S')\n",
    "batse_long = group.get_group('L')\n",
    "batse_s = [d for d in duration_data_b.loc[batse_short.GRBname,'T90']]\n",
    "batse_l = [d for d in duration_data_b.loc[batse_long.GRBname,'T90']]\n",
    "\n",
    "fig, axs = plt.subplots(3,figsize=(8,6),constrained_layout=True)\n",
    "#figure out how to do logarithmic ticks\n",
    "plt.xlabel('log$T_{90}$',size=14)\n",
    "plt.ylabel('Count',size=14)\n",
    "axs[0].set_title('Swift',size=16)\n",
    "axs[0].hist(np.log10(duration_data_s.loc[swift_short.GRBname,'T90']), range = (-3,4), bins = 45, color = 'C1', edgecolor = 'C1', alpha = 0.5)\n",
    "axs[0].hist(np.log10(duration_data_s.loc[swift_long.GRBname,'T90']), range = (-3,4), bins = 45, color = 'C2', edgecolor = 'C2', alpha = 0.5)\n",
    "axs[0].legend(['short','long'], loc='upper left')\n",
    "axs[1].set_title('Fermi',size=16)\n",
    "axs[1].hist(np.log10(duration_data_f.loc[fermi_short.GRBname,'T90']), range = (-3,4), bins = 45, color = 'C1', edgecolor = 'C1', alpha = 0.5)\n",
    "axs[1].hist(np.log10(duration_data_f.loc[fermi_long.GRBname,'T90']), range = (-3,4), bins = 45, color = 'C2', edgecolor = 'C2', alpha = 0.5)\n",
    "axs[1].legend(['short','long'], loc='upper left')\n",
    "axs[2].set_title('BATSE',size=16)\n",
    "axs[2].hist(np.log10(duration_data_b.loc[batse_short.GRBname,'T90']), range = (-3,4), bins = 45, color = 'C1', edgecolor = 'C1', alpha = 0.5)\n",
    "axs[2].hist(np.log10(duration_data_b.loc[batse_long.GRBname,'T90']), range = (-3,4), bins = 45, color = 'C2', edgecolor = 'C2', alpha = 0.5)\n",
    "axs[2].legend(['short','long'], loc='upper left')\n",
    "#plt.savefig('duration_comparison.jpg',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1bfc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "hardness_data_s = pd.read_pickle('DataFrames/hardness_data.dat')\n",
    "hardness_data_b = pd.read_pickle('DataFrames/hardness_data_BATSE.dat')\n",
    "\n",
    "fig, axs = plt.subplots(2,1,figsize=(4,8),constrained_layout=True)\n",
    "axs[0].set_title('Swift',size=16)\n",
    "axs[0].set_xlabel('log$T_{90}$',size=12)\n",
    "axs[0].set_ylabel('$s(50-100)/s(25-50)$',size=12)\n",
    "#axs[0].scatter(np.log10(duration_data_s.loc[swift_short.GRBname,'T90']), hardness_data_s.loc[swift_short.GRBname,'hardness'], c='C1', marker='x')\n",
    "#axs[0].scatter(np.log10(duration_data_s.loc[swift_long.GRBname,'T90']), hardness_data_s.loc[swift_long.GRBname,'hardness'], c='C2', marker='x')\n",
    "s1 = sns.kdeplot(x=np.log10(duration_data_s.loc[swift_short.GRBname,'T90']), y=hardness_data_s.loc[swift_short.GRBname,'hardness'], bw_adjust=0.6, clip=((-2,3),(-0.1,5.2)), levels=5, thresh=0.1, ax=axs[0], color=plt.cm.Dark2.colors[1], fill=False, alpha=0.75)\n",
    "s2 = sns.kdeplot(x=np.log10(duration_data_s.loc[swift_long.GRBname,'T90']), y=hardness_data_s.loc[swift_long.GRBname,'hardness'], bw_adjust=0.6, clip=((-2,3),(-0.1,5.2)), levels=5, thresh=0.1, ax=axs[0], color=plt.cm.Dark2.colors[2], fill=False, alpha=0.75)\n",
    "#axs[0].legend(['short','long'], loc='upper right')\n",
    "axs[1].set_title('BATSE',size=16)\n",
    "axs[1].set_xlabel('log$T_{90}$',size=12)\n",
    "axs[1].set_ylabel('$s(50-100)/s(20-50)$',size=12)\n",
    "#axs[1].scatter(np.log10(duration_data_b.loc[batse_short.GRBname,'T90']), hardness_data_b.loc[batse_short.GRBname,'hardness'], c='C1', marker='x')\n",
    "#axs[1].scatter(np.log10(duration_data_b.loc[batse_long.GRBname,'T90']), hardness_data_b.loc[batse_long.GRBname,'hardness'], c='C2', marker='x')\n",
    "b1 = sns.kdeplot(x=np.log10(duration_data_b.loc[batse_short.GRBname,'T90']), y=hardness_data_b.loc[batse_short.GRBname,'hardness'], bw_adjust=0.5, clip=((-2,3),(-0.1,5.2)), levels=5, thresh=0.1, ax=axs[1], color=plt.cm.Dark2.colors[1], fill=False, alpha=0.75)\n",
    "b2 = sns.kdeplot(x=np.log10(duration_data_b.loc[batse_long.GRBname,'T90']), y=hardness_data_b.loc[batse_long.GRBname,'hardness'], bw_adjust=0.5, clip=((-2,3),(-0.1,5.2)), levels=5, thresh=0.1, ax=axs[1], color=plt.cm.Dark2.colors[2], fill=False, alpha=0.75)\n",
    "#axs[1].legend(['short','long'], loc='upper right')\n",
    "plt.savefig('DataFrames/hardness_comparison.jpg',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2664b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_data_s = pd.read_pickle('DataFrames/duration_data.dat')\n",
    "classification = pd.read_csv('DataFrames/classification_Swift.txt')\n",
    "group = classification.groupby(classification.type)\n",
    "swift_short = group.get_group('S')\n",
    "swift_long = group.get_group('L')\n",
    "swift_s = [d for d in duration_data_s.loc[swift_short.GRBname,'T90']]\n",
    "swift_l = [d for d in duration_data_s.loc[swift_long.GRBname,'T90']]\n",
    "\n",
    "duration_data_f = pd.read_pickle('DataFrames/duration_data_Fermi.dat')\n",
    "classification = pd.read_csv('DataFrames/classification_Fermi.txt')\n",
    "group = classification.groupby(classification.type)\n",
    "fermi_short = group.get_group('S')\n",
    "fermi_long = group.get_group('L')\n",
    "fermi_s = [d for d in duration_data_f.loc[fermi_short.GRBname,'T90']]\n",
    "fermi_l = [d for d in duration_data_f.loc[fermi_long.GRBname,'T90']]\n",
    "\n",
    "duration_data_b = pd.read_pickle('DataFrames/duration_data_BATSE.dat')\n",
    "classification = pd.read_csv('DataFrames/classification_BATSE.txt')\n",
    "group = classification.groupby(classification.type)\n",
    "batse_short = group.get_group('S')\n",
    "batse_long = group.get_group('L')\n",
    "batse_s = [d for d in duration_data_b.loc[batse_short.GRBname,'T90']]\n",
    "batse_l = [d for d in duration_data_b.loc[batse_long.GRBname,'T90']]\n",
    "\n",
    "fig, axs = plt.subplots(3,figsize=(8,6),constrained_layout=True)\n",
    "#figure out how to do logarithmic ticks\n",
    "plt.xlabel('log$T_{90}$', size=14)\n",
    "axs[1].set_ylabel('Count (Normalized)', size=14)\n",
    "axs[0].set_title('Swift', size=16)\n",
    "axs[0].hist(np.log10(duration_data_s.loc[swift_short.GRBname,'T90']), density=True, range = (-3,4), bins = 45, color = 'C1', edgecolor = 'C1', alpha = 0.5)\n",
    "axs[0].hist(np.log10(duration_data_s.loc[swift_long.GRBname,'T90']), density=True, range = (-3,4), bins = 45, color = 'C2', edgecolor = 'C2', alpha = 0.5)\n",
    "axs[0].legend(['short','long'], loc='upper left')\n",
    "axs[1].set_title('Fermi', size=16)\n",
    "axs[1].hist(np.log10(duration_data_f.loc[fermi_short.GRBname,'T90']), density=True, range = (-3,4), bins = 45, color = 'C1', edgecolor = 'C1', alpha = 0.5)\n",
    "axs[1].hist(np.log10(duration_data_f.loc[fermi_long.GRBname,'T90']), density=True, range = (-3,4), bins = 45, color = 'C2', edgecolor = 'C2', alpha = 0.5)\n",
    "axs[1].legend(['short','long'], loc='upper left')\n",
    "axs[2].set_title('BATSE', size=16)\n",
    "axs[2].hist(np.log10(duration_data_b.loc[batse_short.GRBname,'T90']), density=True, range = (-3,4), bins = 45, color = 'C1', edgecolor = 'C1', alpha = 0.5)\n",
    "axs[2].hist(np.log10(duration_data_b.loc[batse_long.GRBname,'T90']), density=True, range = (-3,4), bins = 45, color = 'C2', edgecolor = 'C2', alpha = 0.5)\n",
    "axs[2].legend(['short','long'], loc='upper left')\n",
    "for ax in axs:\n",
    "    ax.set_xlim(-2, 3.5)\n",
    "plt.savefig('duration_comparison_normalized.jpg',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc9893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.read_pickle('DataFrames/stability_Swift.dat')\n",
    "f = pd.read_pickle('DataFrames/stability_Fermi.dat')\n",
    "b = pd.read_pickle('DataFrames/stability_BATSE.dat')\n",
    "\n",
    "emb_s = pd.read_csv(\"embedding_TSNE_20.csv\", header = None, index_col = 0)\n",
    "emb_f = pd.read_csv(\"embedding_TSNE_Fermi_20.csv\", header = None, index_col = 0)\n",
    "emb_b = pd.read_csv(\"embedding_TSNE_BATSE.csv\", header = None, index_col = 0)\n",
    "\n",
    "fig, axs = plt.subplots(1,3,figsize=(12,4),constrained_layout=True)\n",
    "fig.suptitle('Stability', size=18)\n",
    "axs[0].set_title('Swift', size=14)\n",
    "axs[0].scatter(emb_s[1], emb_s[2], s=5, c=s.loc[:,'%'])\n",
    "axs[0].set(xticks=(), yticks=())\n",
    "axs[1].set_title('Fermi', size=14)\n",
    "axs[1].scatter(emb_f[1], emb_f[2], s=5, c=f.loc[:,'%'])\n",
    "axs[1].set(xticks=(), yticks=())\n",
    "axs[2].set_title('BATSE', size=14)\n",
    "axs[2].scatter(emb_b[1], emb_b[2], s=5, c=b.loc[:,'%'])\n",
    "axs[2].set(xticks=(), yticks=())\n",
    "cbar = plt.colorbar(axs[2].get_children()[0], ax=axs[2], location = 'right')\n",
    "cbar.set_label('$\\max\\{P(X \\in L),P(X \\in S)\\}$', size=12)\n",
    "#fig.savefig('stability_all.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48566b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\"summary/Basic_BATSE_new.dat\", sep=\"\\s+\", comment='#', header=None, usecols=[0,2],index_col=0)\n",
    "#df\n",
    "#df[df[2].str.contains('-')]\n",
    "for i in range(len(df)):\n",
    "    df.iloc[i,0] = 'GRB' + df.iloc[i,0]\n",
    "    if df.iloc[i,:].str.contains('-').iloc[0]:\n",
    "        if df.iloc[i,0][:-1] == df.iloc[i-1,0][:-1]:\n",
    "            df.iloc[i,0] = df.iloc[i,0][:-1] + ['A','B','C','D','E'][['A','B','C','D','E'].index(df.iloc[i-1,0][-1])+1]\n",
    "        else:\n",
    "            df.iloc[i,0] = df.iloc[i,0][:-1] + 'A'\n",
    "df.columns = ['Name']\n",
    "df.loc[2464] = 'GRB930725B'\n",
    "df = df.loc[pd.read_csv('DataFrames/classification_BATSE.txt', index_col=0).index]\n",
    "df.index.name = 'trig'\n",
    "df = df.sort_values('trig')\n",
    "for i in ['Other Name', 'Type', 'BATSE Type', 'BATSE Prob.', 'Swift Type', 'Swift Prob.', 'Fermi Type', 'Fermi Prob.']:\n",
    "    df[i] = ''\n",
    "df = df.set_index('Name')\n",
    "display(df)\n",
    "df.to_pickle('DataFrames/complete_catalog.dat')\n",
    "#print(df.to_latex())\n",
    "#print(df.set_index('name'))#[:,'name'])\n",
    "#pd.read_csv('DataFrames/classification_BATSE.txt', index_col=0).loc[2464]\n",
    "#df.to_pickle('DataFrames/names_from_trig_BATSE.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b117ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('DataFrames/complete_catalog.dat')\n",
    "df = pd.concat((df,pd.read_csv('embedding_TSNE_20.csv',index_col=0,header=None).index.to_series()),0).drop(columns=[0])\n",
    "df.index.name = 'Name'\n",
    "df.columns = ['Other Name', 'Type', 'BATSE Type', 'BATSE Prob.', 'Swift Type', 'Swift Prob.', 'Fermi Type', 'Fermi Prob.']\n",
    "for i in ['Other Name', 'Type', 'BATSE Type', 'BATSE Prob.', 'Swift Type', 'Swift Prob.', 'Fermi Type', 'Fermi Prob.']:\n",
    "    df[i] = ''\n",
    "display(df)\n",
    "df.to_pickle('DataFrames/complete_catalog.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('DataFrames/complete_catalog.dat')\n",
    "intersection = pd.read_csv('DataFrames/intersection_Swift_Fermi.csv')\n",
    "for index, burst in enumerate(intersection.Swift):\n",
    "    pass\n",
    "    #df.loc[burst, 'Other Name'] = intersection.loc[index,'Fermi']\n",
    "display(df)\n",
    "df.to_pickle('DataFrames/complete_catalog.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c455ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_table('Downloads/Summary_table.txt', sep = '\\s+', skiprows=[0,2], index_col='GRB_name', usecols = [0,1])\n",
    "table.loc['GRB091024372'] = 'GRB091024A'\n",
    "table.loc['GRB091024380'] = 'GRB091024B'\n",
    "table.loc['GRB130925173'] = 'GRB130925'\n",
    "#'GRB080916406'\n",
    "table = table.loc[pd.read_csv('DataFrames/classification_Fermi.txt', index_col=0).index]\n",
    "#table = table.loc[pd.read_csv('DataFrames/intersection_Swift_Fermi.csv', index_col='Fermi').index]\n",
    "#\n",
    "\n",
    "swift = pd.read_csv('DataFrames/intersection_Swift_Fermi.csv', index_col=0).index\n",
    "for i in range(len(table)):\n",
    "    if table.iloc[i,0][:-1] in swift and table.reset_index().iloc[i,0] == table.reset_index().iloc[swift.get_loc(table.iloc[i,0][:-1]),0]:\n",
    "        print(table.iloc[i,0])\n",
    "        table.iloc[i,0] = table.iloc[i,0][:-1]\n",
    "for i in range(len(table)):\n",
    "    if table.iloc[i,0][-1] == '*':\n",
    "        table.iloc[i,0] = table.iloc[i,0][:-1]\n",
    "for i in range(len(table)):\n",
    "    if int(table.iloc[i,0][3:5]) < 10:\n",
    "        if table.iloc[i,0][-1] == 'A' and table.iloc[i,0][:-1] != table.iloc[i+1,0][:-1]:\n",
    "            table.iloc[i,0] = table.iloc[i,0][:-1]\n",
    "table = table.reset_index()#.set_index('#')\n",
    "table.columns = ['Other Name', 'Name']\n",
    "table = table.set_index('Name')\n",
    "display(table)\n",
    "#table.loc[pd.read_csv('DataFrames/classification_Swift.txt', index_col=0).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac9d069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('DataFrames/complete_catalog.dat')\n",
    "for index, burst in enumerate(table.index):\n",
    "    df.loc[burst] = table.iloc[index,0]\n",
    "for i in range(len(df)):\n",
    "    name = df.index.tolist()[i]\n",
    "    if int(name[3]) == 9:\n",
    "        num = '19'\n",
    "    else:\n",
    "        num = '20'\n",
    "    df = df.rename(index={name : (name[:3] + num + name[3:])})\n",
    "df = df.sort_index(kind='stable')\n",
    "for i in range(len(df)):\n",
    "    name = df.index.tolist()[i]\n",
    "    df = df.rename(index={name : name[:3] + name[5:]})\n",
    "dupes = []\n",
    "for i in range(len(df)-1):\n",
    "    if df.index[i] == df.index[i+1][:-1]:\n",
    "        print(df.index[i])\n",
    "        dupes.append(df.index[i])\n",
    "#df = df.drop(dupes)\n",
    "df.index.name = 'Name'\n",
    "df.columns = ['Other Name', 'Type', 'BATSE Type', 'BATSE Prob.', 'Swift Type', 'Swift Prob.', 'Fermi Type', 'Fermi Prob.']\n",
    "for i in ['Type', 'BATSE Type', 'BATSE Prob.', 'Swift Type', 'Swift Prob.', 'Fermi Type', 'Fermi Prob.']:\n",
    "    df[i] = ''\n",
    "display(df)\n",
    "df.to_pickle('DataFrames/complete_catalog.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1fbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('DataFrames/complete_catalog.dat')\n",
    "names = pd.read_pickle('DataFrames/names_from_trig_BATSE.dat')\n",
    "classification = pd.read_csv('DataFrames/classification_BATSE.txt', index_col=0)\n",
    "stability = pd.read_pickle('DataFrames/stability_BATSE.dat')\n",
    "mismatch = pd.read_csv('DataFrames/mismatching_bursts_BATSE.txt', index_col=0)\n",
    "for trig in names.index:\n",
    "    name = names.loc[trig,'Name']\n",
    "    t = classification.loc[trig,'type']\n",
    "    df.loc[name,'Type'] = t\n",
    "    df.loc[name,'BATSE Type'] = t\n",
    "    if stability.loc[str(trig),'%'] < 0.9:\n",
    "        df.loc[name,'Type'] = 'A'\n",
    "        df.loc[name,'BATSE Type'] = 'A'\n",
    "    elif trig in mismatch.index:\n",
    "        df.loc[name,'Type'] = 'D'\n",
    "        df.loc[name,'BATSE Type'] = 'D'\n",
    "    df.loc[name,'BATSE Prob.'] = round(abs(int(t=='L') - stability.loc[str(trig),'%']),2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff744ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = pd.read_csv('DataFrames/classification_Swift.txt', index_col=0)\n",
    "stability = pd.read_pickle('DataFrames/stability_Swift.dat')\n",
    "mismatch = []\n",
    "for trig in classification.index:\n",
    "    t = classification.loc[trig,'type']\n",
    "    #df.loc[trig,'Type'] = t\n",
    "    df.loc[trig,'Swift Type'] = t\n",
    "    if stability.loc[str(trig),'%'] < 0.9:\n",
    "        #df.loc[trig,'Type'] = 'A'\n",
    "        df.loc[trig,'Swift Type'] = 'A'\n",
    "    elif trig == 'GRB090813':\n",
    "        #df.loc[trig,'Type'] = 'D'\n",
    "        df.loc[trig,'Swift Type'] = 'D'\n",
    "    elif trig in ['GRB050724','GRB121226A','GRB180418A']:\n",
    "        #df.loc[trig,'Type'] = 'D'\n",
    "        df.loc[trig,'Swift Type'] = 'D'\n",
    "    df.loc[trig,'Swift Prob.'] = round(abs(int(t=='L') - stability.loc[str(trig),'%']),2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = pd.read_csv('DataFrames/classification_Fermi.txt', index_col=0)\n",
    "stability = pd.read_pickle('DataFrames/stability_Fermi.dat')\n",
    "mismatch = []\n",
    "for trig in classification.index:\n",
    "    index = df.index.tolist()[pd.Index(df.loc[:,'Other Name']).get_loc(trig)]\n",
    "    t = classification.loc[trig,'type']\n",
    "    #df.loc[index,'Type'] = t\n",
    "    df.loc[index,'Fermi Type'] = t\n",
    "    if stability.loc[str(trig),'%'] < 0.9:\n",
    "        #df.loc[index,'Type'] = 'A'\n",
    "        df.loc[index,'Fermi Type'] = 'A'\n",
    "    elif trig in ['GRB080828189','GRB090811696','GRB110719825','GRB110728056']:\n",
    "        #df.loc[index,'Type'] = 'D'\n",
    "        df.loc[index,'Fermi Type'] = 'D'\n",
    "    df.loc[index,'Fermi Prob.'] = round(abs(int(t=='L') - stability.loc[str(trig),'%']),2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66154758",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.Type=='','Type'] = np.where((df['BATSE Type'] == '') & ((df['Swift Type'] == '') | (df['Fermi Type'] == '')),(df['Swift Type'] + df['Fermi Type']),'')[df.Type=='']\n",
    "sub = df.loc[(df.loc[:,'Swift Type'] != '') & (df.loc[:,'Fermi Type'] != '')]\n",
    "sub['Type'] = np.where((sub['Swift Type'] == sub['Fermi Type']), sub['Swift Type'], '')\n",
    "sub.loc[sub.Type=='','Type'] = np.where((sub['Swift Type'] == 'L') & (sub['Fermi Type'] == 'S'), 'O', '')[sub.Type=='']\n",
    "sub.loc[sub.Type=='','Type'] = np.where((sub['Swift Type'] != 'A'), sub['Swift Type'], sub['Fermi Type'])[sub.Type=='']\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(sub)\n",
    "df.loc[sub.index,'Type'] = sub['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f33465",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    #display(df)\n",
    "    display(pd.read_pickle('DataFrames/complete_catalog.dat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fff2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_pickle('DataFrames/complete_catalog.dat')\n",
    "df.to_csv('DataFrames/complete_catalog.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4b9b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "swift_burst = 'GRB170318B'\n",
    "fermi_burst = pd.read_csv('DataFrames/intersection_Swift_Fermi.csv',index_col=0).loc[swift_burst]\n",
    "print(pd.read_pickle('DataFrames/duration_data.dat').loc[swift_burst])\n",
    "print()\n",
    "print(pd.read_pickle('DataFrames/duration_data_Fermi.dat').loc[fermi_burst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d43dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.reset_index().to_latex(columns = ['Name', 'Other Name', 'Type', 'BATSE Type', 'BATSE Prob.', 'Swift Type', 'Swift Prob.', 'Fermi Type', 'Fermi Prob.'], index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5782fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DataFrames/classification_Swift.txt', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93738a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_table('Downloads/Summary_table.txt', sep = '\\s+', skiprows=[0,2], index_col='#', usecols = [0,1])\n",
    "table = table.loc[pd.read_csv('DataFrames/classification_Swift.txt', index_col=0).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dfd4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('DataFrames/duration_data_Fermi.dat').loc['GRB130925173']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46824b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = pd.read_csv('DataFrames/intersection_Swift_Fermi.csv').iloc[::-1]\n",
    "Swift = pd.DataFrame(pd.read_pickle('DataFrames/duration_data.dat').loc[:,'T90']).reset_index().iloc[::-1]\n",
    "Swift = Swift[Swift.isin(intersection.Swift.tolist()).GRBname].reset_index(drop=True)\n",
    "for i in range(Swift.shape[0]):\n",
    "    if Swift.iloc[i,1] > 2:\n",
    "        Swift.iloc[i,1] = 'L ' + str(Swift.iloc[i,1])\n",
    "    else:\n",
    "        Swift.iloc[i,1] = 'S ' + str(Swift.iloc[i,1])\n",
    "display(Swift)\n",
    "Fermi = pd.DataFrame(pd.read_pickle('DataFrames/duration_data_Fermi.dat').loc[:,'T90']).reset_index()\n",
    "Fermi = Fermi[Fermi.isin(intersection.Fermi.tolist()).name].reset_index(drop=True)\n",
    "for i in range(Fermi.shape[0]):\n",
    "    if Fermi.iloc[i,1] > 2:\n",
    "        Fermi.iloc[i,1] = 'L ' + str(Fermi.iloc[i,1])\n",
    "    else:\n",
    "        Fermi.iloc[i,1] = 'S ' + str(Fermi.iloc[i,1])\n",
    "display(Fermi)\n",
    "classification = pd.concat([Swift,Fermi], axis=1)\n",
    "classification = classification[classification.iloc[:,1].str[0] != classification.iloc[:,3].str[0]].reset_index(drop=True)\n",
    "classification.columns = ['Swift', 'type', 'Fermi', 'type']\n",
    "display(classification)\n",
    "#classification.set_index('Swift').to_csv('DataFrames/duration_disagreement.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dcde0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_pickle('DataFrames/complete_catalog.dat').to_csv('DataFrames/complete_catalog.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
